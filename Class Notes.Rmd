---
title: "Class Notes"
output:
  html_document:
    toc: true
    toc_float: true
    collapsed: false
    number_sections: false
    toc_depth: 1
    #code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=FALSE,
                      warning=FALSE,
                      cache=TRUE)
```

#02/25/18
##GGplot2 & dataframes

Table for a data frame:
srt dim age subject live
200 dim 17  1     bk
300 bright

```{r}
Namess<- c("peter","paul","mary",NA)
Ages <- c(1000,1200,100,50) #if you have a 4th variable in only one category then you have to add NA in the others so it equals in length
Sex<- c("M","M","F",NA)

my_df<-data.frame(Names = Namess,
                  Age = Ages,
                  Sex = Sex)
#my_df$ #gives you all the columns

#names is saved as a factor

#my_df$Namess<-as.character(my_df$Namess)
```

once you get data into a long format table, the graph is easy
```{r}
library(ggplot2)
# Create dataframe
a <- c(1,2,3,2,3,4,5,4)
b <- c(4,3,4,3,2,1,2,3)
plot_df <- data.frame(a,b)

# basic scatterplot
ggplot(data =plot_df, aes(x=a,y=b))+
  geom_point()

```

```{r}
# customize, add regression line
ggplot(data = plot_df, aes(x=a,y=b))+
  geom_point(size=2)+
  geom_smooth(method=lm)+
  coord_cartesian(xlim=c(0,7),ylim=c(0,10))+  #controls the range of the graph (left to right)
  xlab("x-axis label")+
  ylab("y-axis label")+
  ggtitle("I made a scatterplot")+
  theme_classic(base_size=12)+  #changes the background & controls the font size, guaranteeing that it will stay that way.
  theme(plot.title = element_text(hjust = 0.5))

```



```{r}
#Create a dataframe
factor_one <- as.factor(c("A","B","C"))
dv_means <- c(20,30,40)
dv_SEs   <- c(4,3.4,4)
plot_df <- data.frame(factor_one,
                      dv_means,
                      dv_SEs)

# basic bar graph

ggplot(plot_df, aes(x=factor_one,y=dv_means))+ #set what will be x axis and what will be the y axis. have a plus to tell it you're adding another layer
  geom_bar(stat="identity") #stat = identity means dont touch the data statistically just plot it as is.
```


```{r}
# adding error bars, customizing

ggplot(plot_df, aes(x=factor_one,y=dv_means))+
  geom_bar(stat="identity")+
  geom_errorbar(aes(ymin=dv_means-dv_SEs,
                    ymax=dv_means+dv_SEs),
                width=.2)+
  coord_cartesian(ylim=c(0,100))+
  xlab("x-axis label")+
  ylab("y-axis label")+
  ggtitle("I made a bar graph")+
  theme_classic(base_size=12)+
  theme(plot.title = element_text(hjust = 0.5))
```


```{r}
#Create a dataframe
factor_one <- rep(as.factor(c("A","B","C")),2)
factor_two <- rep(as.factor(c("IIA","IIB")),3)
dv_means <- c(20,30,40,20,40,40)
dv_SEs   <- c(4,3.4,4,3,2,4)
plot_df <- data.frame(factor_one,
                      factor_two,
                      dv_means,
                      dv_SEs)

# basic bar graph

ggplot(plot_df, aes(x=factor_one,y=dv_means,
                    group=factor_two,
                    color=factor_two, # color = only for border
                    fill=factor_two))+
  geom_bar(stat="identity", position="dodge",color="black") #dodge makes the bars next to each other, without dodge theyre on top of each other

```


```{r}
# adding error bars, customizing

ggplot(plot_df, aes(x=factor_one,y=dv_means,
                    group=factor_two,
                    color=factor_two,
                    fill=factor_two))+
  geom_bar(stat="identity", position="dodge")+
  geom_errorbar(aes(ymin=dv_means-dv_SEs,
                    ymax=dv_means+dv_SEs),
                position=position_dodge(width=0.9), #important to make error bars look right
                width=.2,
                color="black")+
  coord_cartesian(ylim=c(0,100))+
  xlab("x-axis label")+
  ylab("y-axis label")+
  ggtitle("Bar graph 2 factors")+
  theme_classic(base_size=12)+
  theme(plot.title = element_text(hjust = 0.5))
```


```{r}
#Create a dataframe
factor_one <- rep(rep(as.factor(c("A","B","C")),2),2)
factor_two <- rep(rep(as.factor(c("IIA","IIB")),3),2)
factor_three <- rep(as.factor(c("IIIA","IIIB")),each=6)
dv_means <- c(20,30,40,20,40,40,
              10,20,50,50,10,10)
dv_SEs   <- c(4,3.4,4,3,2,4,
              1,2,1,2,3,2)
plot_df <- data.frame(factor_one,
                      factor_two,
                      factor_three,
                      dv_means,
                      dv_SEs)

# basic bar graph

ggplot(plot_df, aes(x=factor_one,y=dv_means,
                    group=factor_two,
                    color=factor_two))+
  geom_bar(stat="identity", position="dodge")+
  facet_wrap(~factor_three) # breaks it into 2 graphs
```


```{r}
Namez<- rep(c("Dara","Azalea","Barbi","Rowena","Fiona" ),each=2)
MF <- rnorm(10,45,25)
Condition <- rep(c("Social", "Nonsocial"),5)
Aversion <- rep(c("A","N_A"),times=c(4,6))
plot_df<- data.frame(Namez,MF,Condition,Aversion)

ggplot(plot_df, aes(x=Condition, y=MF, group=Namez,linetype=Aversion))+
  geom_line()+
  geom_text(label=Namez)+
  theme_classic()

```



#03/04/19 Snow Day

## What is Data-wrangling

Data-wrangling is the general process of organizing and transforming data into various formats. For example, loading data into R, pre-processing it to get rid of things you don't want and keep the things you want, add new things you might want that, arranging the data in different ways to accomplish different kinds of tasks, grouping the data, and summarizing the data, are all common data-wrangling activities. Real-world data often has many imperfections, so data-wrangling is necessary to get the data into a state that is readily analyzable.

We will mainly go over the `dplyr` package, which has a number of fantastic and relatively easy to use tools for data-wrangling. At the same time, it worth developigng your basic programming skills (using loops and logic), as they are also indispensable for solving unusual data-wrangling problems.

## dplyr basics

1. [Dplyr reference](https://dplyr.tidyverse.org)
2. [Hadley Wickham's, R for Data Science, Chapter 5 Data transformation](http://r4ds.had.co.nz/transform.html)

```{r}
library(dplyr) #load the package (make sure it is installed first)
df <- starwars # dplyr comes with a data.frame called starwars
```

Take a look at that data in df, what do you see? It lists various characters from starwars, along with many columns that code for different properties of each character

## basic dataframe stuff without dplyr

```{r, eval=F}
# addressing specific columns
df$name 
df$height
df$mass
# addressing columns and rows without names
df[1,] # row 1
df[,1] # column 1
df[1:4,] # all of the data in rows 1:4
df[,4:5] # all of the data in columns 4:5
df[1:3,6:7] # the data in rows 1 to 3, for column 6 and 7 only
# finding a row(s) with specific info
df[df$name=="Luke Skywalker",]
df[df$height > 180,]
df[df$height < 180 & df$height > 70,]
#replace a particular value
df[1,2] <- 173 #changes the cell in row 1 column 2
# size of dataframe
dim(df) #c(number of rows, number of columns)
# cbind to add a column to a data.frame
df <- cbind(df, random_number=runif(dim(df)[1],0,1))
# rbind to add rows
# this creates a new data frame, binding together the rows 1-2, and 5-6
# note: all of the columns need to be the same
new_df <- rbind(df[1:2,],df[5:6,]) 
# convert a character vector to a factor
df$species <- as.factor(df$species)
levels(df$species)
levels(df$species)[3] <- "hello" # renames the third level, which get's applied to all listings in the df
```

## A couple questions:

1. What are the names of all the characters who are taller than 80, shorter than 140, and are female?

```{r, eval=F}
df[df$height > 80 &
     df$height < 170 &
     df$gender == "female", ]$name
```

2. How many characters have Tatooine for their homeworld?

```{r, eval=F}
df[df$homeworld=="Tatooine",]
dim(df[df$homeworld=="Tatooine",])[1] # counts the NAs
tatooine <- df[df$homeworld=="Tatooine",]
tatooine[is.na(tatooine$name)==FALSE,]
dim(tatooine[is.na(tatooine$name)==FALSE,])[1]
```

## dplyr style

We now look at dplyr and pipes. The idea here is that we start with a dataframe, then systematically transform one step at a time. At each step we pass the data in it's new state to the next step. The passing is called piping the data. There is a special operator for this `%>%`

### quick example

We start with the entire dataframe `df`. Then we select only the rows where the height is taller than 100. Then we group by homeworld, and compute the mean birth year. What we get is a new data.frame, showing the mean birth years for each homeworld. 

This is a common refrain:

Dataframe %>% filter %>% group_by %>% summarise

```{r}
library(dplyr)

new_df <- df %>%
            filter(height > 100) %>%
            group_by(homeworld) %>%
            summarise(mean_birth_year = mean(birth_year,na.rm=TRUE))
```


### filter

We can filter the data by properties of particular columns

```{r}
# make a new dataframe that only include rows where the height is greater than 120
new_df <- df %>%
        filter(height > 120)
# multiple filters are seperated by a comma
new_df <- df %>%
        filter(height > 120,
               height < 180,
               birth_year > 20)
# more examples of differen logical operators
new_df <- df %>%
        filter(gender == "male") # == equals identity (same as)
new_df <- df %>%
        filter(gender != "male") # != not equal to
new_df <- df %>%
        filter(eye_color %in% c("blue","yellow") == TRUE) # looks for matches to blue and yellow
# <= less than or equal to
# >= greater than or equal to
new_df <- df %>%
        filter(height >= 120,
               height <= 180) 
new_df <- df %>%
        filter(height > 120 & height < 180) # &  AND
new_df <- df %>%
        filter(skin_color == "fair" | skin_color == "gold") # | OR
```

### group_by and summarise

`group_by()` let's us grab parts of the data based on the levels in the column

`summarise()` applies a function to each of the groups that are created

```{r}
# counts the number of names, for each hair color
new_df <- df %>%
          group_by(hair_color) %>%
          summarise(counts=length(name))
# counts names, for each combination of hair and eye color
new_df <- df %>%
          group_by(hair_color,eye_color) %>%
          summarise(counts=length(name))
```

### focus on summarise

`summarise` is very powerful. Using summarise we can apply any function we want to each of the groups. This includes intrinsic R functions, and functions of our own design. And, we can add as many as we want. What we get back are new dataframes with columns for each group, and new columns with variables containing the data we want from the analysis

```{r, eval = FALSE}
new_df <- df %>%
          group_by(hair_color,eye_color) %>%
          summarise(mean_years = mean(birth_year,na.rm=TRUE),
                    sd_years = sd(birth_year,na.rm=TRUE),
                    counts = length(name))
```

### Mutate

Use mutate to change or add a column

```{r}
# change numbers in the height column by subtracting 100
library(dplyr)
new_df <- df %>%
            mutate(height=height-100)
# make a new column dividing height by mass
new_df <- df %>%
            mutate(hm_ratio = height/mass)
```

### Select

Use select to select columns of interest and return a dataframe only with those columns

```{r}
new_df <- df %>%
            select(name,height,mass)
```

### Star wars questions and answers

1. use dplyr to find how many movies each character appeared in. Return a table that lists the names, and the number of films

```{r}
# two ways to do the same thing
new_df <- df %>% 
            select(name,films) %>%
            group_by(name) %>%
            mutate(films = length(unlist(films)))
new_df <- df %>% 
            select(name,films) %>%
            group_by(name) %>%
            summarise(films = length(unlist(films)))
```


2. How many characters are in each movie?

- dplyr isn't always necessary for every question

```{r}
table(unlist(df$films))
```

3. What is the mean height and mass of characters with blue eyes?

```{r}
new_df <- df %>%
            filter(eye_color=="blue") %>%
            summarise(mean_height = mean(height,na.rm=TRUE),
                      mean_mass = mean(mass,na.rm=TRUE))
```

## Data input

Before we wrangle with data, we need to get it into R. There are many ways to do that. 

All of the following examples assume you have a data folder in your workspace that contains all the data files we will be using. Download this .zip file [https://github.com/CrumpLab/statisticsLab/raw/master/RstudioCloud.zip](https://github.com/CrumpLab/statisticsLab/raw/master/RstudioCloud.zip). Unzip the file. Then copy the data folder into your R markdown project folder.

**WARNING:** loading files requires you to tell R exactly where the file is on your computer. This can involve specifying the entire file path (the drive, all of the folder, and then the filename). These examples avoid this complete filename nonsense by putting the files in a data folder in your R project folder. Then, we just need to specify the folder and the filename. In this case, the folder will always be data. In general, R by default attempts to load files from the current working directory, which is automatically set to your project folder when you are working in an R-studio project. 

```{r, eval = FALSE}
# loading a csv file using read.csv
hsq <- read.csv("RstudioCloud/data/hsq.csv")
# alternative using fread
library(data.table)
hsq <- fread("RstudioCloud/data/hsq.csv") # creates a data.table, similar to a data.frame
# loading an SPSS sav file
library(foreign)
spss <- read.spss("RstudioCloud/data/02_NYC_Salary_City_2016.sav",
                  to.data.frame=TRUE)
```

### Other helpful libraries for reading in files

1. libary `readxl` let's you read in excel files
2. library `googlesheets` let's you read in google spreadsheets
3. function `scan` is a powerful and all purpose text input function, often helpful in very messy situations where you want to read in line-by-line
4. `load` for R data files
5. there are several `read.` functions for specific situations.
6. library `jsonlite` for json data structures
7. and many more, this is really something that you will learn more about on a case-by-case basis as you have to deal with particular data formats.


#03/11/19 Going over data wrangling 

```{r, eval=FALSE}

#strs(stimulus[1], split="")


```

 fig.path = "myfigs/",
      dev = c("pdf", "png")
      
  ^^ use in 1st chunk to save graphs



#03/18/19 Statistics 

Discussing midterm assignment 
Part 1 (due April 1)
1. make a new github repository. put work into it.
2. find a psych paper with open data.
  - osf.io  = open science framework
  - psychological science (look for blue badge) journals.sagepub.com
  - crumplab/statistics lab
3. load into r
4. re-analyse the data to see if you can reproduce the results from the original paper
5. write it up in reproducible report (.rmd file)

Part 2 (due April 1)
1. Convert your reproducible report into an APA style research report using papaja package.

Part 3 (due April 8)
1. Add a section following the results where you conduct and report a simulation based power analysis


**The most important thing about choosing statistics, is being able to justify the statistics that you choose.**

There are many tools in the toolbox. There are many recommendations about what to do or not to do. It is a good idea to understand the statistics that you use, so that you can justify why you are using them for your analysis.

## t-tests

### one sample t-test

Set `mu` to test against a population value

```{r}
x <- c(1,4,3,2,3,4,3,2,3,2,3,4)
#non-directional
t.test(x, mu = 2)
t.test(x, mu = 2, alternative = "two.sided") # the default
# directional
t.test(x, mu = 2, alternative = "greater")
t.test(x, mu = 2, alternative = "less")
```

t = mean/SEM
SEM tells you how things vary



### paired-sample t-test

Set `paired=TRUE`

```{r}
x <- c(1,4,3,2,3,4,3,2,3,2,3,4)
y <- c(3,2,5,4,3,2,3,2,1,2,2,3)
#non-directional
t.test(x, y, paired=TRUE)
t.test(x, y, paired=TRUE, alternative = "two.sided") # the default
# directional
t.test(x, y, paired=TRUE, alternative = "greater")
t.test(x, y, paired=TRUE, alternative = "less")
```

### Independent sample t-test

Note: Default is Welch test, set `var.equal=TRUE` for t-test

```{r}
x <- c(1,4,3,2,3,4,3,2,3,2,3,4)
y <- c(3,2,5,4,3,2,3,2,1,2,2,3)
#non-directional
t.test(x, y, var.equal=TRUE)
t.test(x, y, var.equal=TRUE, alternative = "two.sided") # the default
# directional
t.test(x, y, var.equal=TRUE, alternative = "greater")
t.test(x, y, var.equal=TRUE, alternative = "less")
```

### printing 

```{r}
library(broom)
t_results <- t.test(x, y, var.equal=TRUE)
knitr::kable(tidy(t_results))
```

### writing

The contents of R variables can be written into R Markdown documents. 

t(`r round(t_results$parameter, digits=2)`) =`r round(t_results$statistic, digits=2)`, p = `r round(t_results$p.value, digits=3)`

```{r}
# write your own function
report_t <- function(x){
  return(paste(c("t(",round(x$parameter, digits=2),") ",
        "= ",round(x$statistic, digits=2),", ",
        "p = ",round(x$p.value, digits=3)), collapse=""))
}
report_t(t_results)
t_results
```


The results of my t-test were `r report_t(t_results)`.


## ANOVA

F = T^2

Effect/Error

SS_Effect/DF1  --> M^2 Eff / 
SS_Error/DF2   --> M^2 Error

Requires data to be in long-format.

```{r}
# example creation of 2x2 data 
Subjects <- rep(1:10,each=4)
Factor1 <- rep(rep(c("A","B"), each = 2), 10)
Factor2 <- rep(rep(c("1","2"), 2), 10)
DV <- rnorm(40,0,1)
all_data <- data.frame(Subjects = as.factor(Subjects),
                       DV,
                       Factor1,
                       Factor2)
```

### between-subjects 1 factor

```{r}
# run anova
aov_out <- aov(DV~Factor1, all_data)
# summary
sum_out <- summary(aov_out)
# kable xtable printing
library(xtable)
knitr::kable(xtable(summary(aov_out)))
# print means
print(model.tables(aov_out,"means"), format="markdown")

sum_out[[1]]$`F value`[1]

#kable function good for making dataframes into pretty table
```

### between-subjects 2 factor

```{r}
# run anova
aov_out <- aov(DV~Factor1*Factor2, all_data)
# summary
summary(aov_out)
# kable xtable printing
library(xtable)
knitr::kable(xtable(summary(aov_out)))
# print means
print(model.tables(aov_out,"means"), format="markdown")
```

### repeated-measures 1 factor

```{r}
# run anova
aov_out <- aov(DV~Factor1 + Error(Subjects/Factor1), all_data)
# summary
summary(aov_out)
# kable xtable printing
library(xtable)
knitr::kable(xtable(summary(aov_out)))
# print means
print(model.tables(aov_out,"means"), format="markdown")
```


### repeated-measures 2 factor

```{r}
# run anova
aov_out <- aov(DV~Factor1*Factor2 + Error(Subjects/(Factor1*Factor2)), all_data)
# summary
summary(aov_out)
# kable xtable printing
library(xtable)
knitr::kable(xtable(summary(aov_out)))
# print means
print(model.tables(aov_out,"means"), format="markdown")
```

### papaja

```{r}
#library(papaja)
#apa_stuff <- apa_print.aov(aov_out)
```
```{r}
#The main effect for factor 1 was, `r apa_stuff$statistic$Factor1`. The main effect for factor 2 was, `r apa_stuff$statistic$Factor2`. The interaction was, `r apa_stuff$statistic$Factor1_Factor2`
```


## Linear Regression

```{r}
lm(DV~Factor1, all_data)
summary(lm(DV~Factor1, all_data))
```

```{r}
lm(DV~Factor1+Factor2, all_data)
summary(lm(DV~Factor1+Factor2, all_data))
```

```{r}
lm(DV~Factor1*Factor2, all_data)
summary(lm(DV~Factor1*Factor2, all_data))
```

## Randomization Test

```{r}
A <- c(1,2,3,4,5,6,7,8,9,10)
B <- c(2,4,6,8,10,12,14,16,18,20)
all <- c(A,B)
mean_difference <- c()
for(i in 1:10000){
  shuffle <- sample(all)
  newA <- shuffle[1:10]
  newB <- shuffle[11:20]
  mean_difference[i] <- mean(newB)-mean(newA)
}
observed <- mean(B)-mean(A)
length(mean_difference[mean_difference >= observed])/10000
library(EnvStats)
twoSamplePermutationTestLocation(x=B, y=A, fcn = "mean", 
                                 alternative = "greater", 
                                 mu1.minus.mu2 = 0, 
                                 paired = FALSE, 
                                 exact = FALSE, 
                                 n.permutations = 10000, 
                                 seed = NULL, 
                                 tol = sqrt(.Machine$double.eps))
```

## Correlation

```{r}
x <- rnorm(10,0,1)
y <- rnorm(10,0,1)
cor(x,y)
ranks1 <- sample(1:10) 
ranks2 <- sample(1:10)
cor(ranks1,ranks2, method = "spearman")
```

## Chi-square

```{r}
M <- as.table(rbind(c(762, 327, 468), c(484, 239, 477)))
dimnames(M) <- list(gender = c("F", "M"),
                    party = c("Democrat","Independent", "Republican"))
(Xsq <- chisq.test(M))
```

## binomial test

```{r}
number_of_successes <- 100
trials <- 150
binom.test(x=number_of_successes, n=trials, p = 0.5,
           alternative = "two.sided",
           conf.level = 0.95)
```

## Post-hoc tests

Many kinds of post-hoc tests can be done in R using base R functions, or functions from other packages. 

At the same time, it is common for post-hoc comparison functions to be limited and specific in their functionality. So, if you can't find an existing function to complete the analysis you want, you may have to modify, extend, or write your own function to do the job. 

### pairwise t-tests

Performs all possible t-tests between the levels of a grouping factor. Can implement different corrections for multiple comparisons.

```{r}
df <- airquality #loads the airquality data from base R
df$Month <- as.factor(df$Month)
# default uses holm correction
pairwise.t.test(df$Ozone,df$Month)
# use bonferroni correction
pairwise.t.test(df$Ozone,df$Month, p.adj="bonf")
```

### tukey HSD test

notes: the warpbreaks data.frame should be available in base R, you do not need to load it to be able to use it.

Doesn't work with repeated measures ANOVAs.

```{r}
summary(fm1 <- aov(breaks ~ wool + tension, data = warpbreaks))
TukeyHSD(fm1, "tension", ordered = TRUE)
```

### Fishers LSD

Explanation of Fisher's least significant difference test.
[https://www.utd.edu/~herve/abdi-LSD2010-pretty.pdf](https://www.utd.edu/~herve/abdi-LSD2010-pretty.pdf)

```{r}
library(agricolae)
data(sweetpotato)
model <- aov(yield~virus, data=sweetpotato)
out   <- LSD.test(model,"virus", p.adj="bonferroni")
```

## Linear Contrasts

```{r}
# Create data for a one-way BW subjects, 4 groups
A <- rnorm(n=10, mean=100, sd=25)
B <- rnorm(n=10, mean=120, sd=25)
C <- rnorm(n=10, mean=140, sd=25)
D <- rnorm(n=10, mean=80, sd=25)
DV <- c(A,B,C,D)
Conditions <- as.factor(rep(c("A","B","C","D"), each=10))
df <- data.frame(DV,Conditions)
# one-way ANOVA
aov_out <- aov(DV~Conditions, df)
summary(aov_out)
# look at the order of levels
levels(df$Conditions)
# set up linear contrasts
c1 <- c(.5, -.5, -.5, .5) # AD vs. BC
c2 <- c(0, 0, 1, -1) # C vs. D
c3 <- c(0, -1, 1, 0) # B vs. C
# create a contrast matrix
mat <- cbind(c1,c2,c3)
# assign the contrasts to the group
contrasts(df$Conditions) <- mat
# run the ANOVA
aov_out <- aov(DV~Conditions, df)
# print the contrasts, add names for the contrasts
summary.aov(aov_out, split=list(Conditions=list("AD vs. BC"=1, "C vs. D" = 2, "B vs. C"=3))) 
```


```{r}
a <- replicate(10000,t.test(rnorm(10,0,1))$p.value)
hist(a)

length(a[a<.05])
```


```{r, eval = FALSE}
Fact1 <- rep(c("A", "B", "C"), each=5)
DV <- rnorm(n=15, mean=0, sd=1)
aov(DV~Fact1, all_data)
```

anova = 
aov(formula, dataframe)
aov(dependent variable ~ Factor, dataframe)
^ for a one factor anova

