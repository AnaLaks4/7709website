<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Class Notes</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>


<style type="text/css">
  p.abstract{
    text-align: center;
    font-weight: bold;
  }
  div.abstract{
    margin: auto;
    width: 90%;
  }
</style>

<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<div class="container-fluid main-container">

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->



<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Ana'sOnlineRJournal</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="Class_Notes.html">Class Notes</a>
</li>
<li>
  <a href="Solving_Problems.html">Solving Problems</a>
</li>
<li>
  <a href="Intrinsics.html">Intrinsics</a>
</li>
<li>
  <a href="GGPlot.html">GGPlot</a>
</li>
<li>
  <a href="DataWrangling.html">DataWrangling</a>
</li>
<li>
  <a href="StatisticsProblems.html">StatisticsProblems</a>
</li>
<li>
  <a href="Links.html">Links</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Class Notes</h1>
<h4 class="author"><em>First Author</em></h4>
<address class="author_afil">
1<br><a class="author_email" href="mailto:#"><a href="mailto:my@email.com">my@email.com</a></a>
</address>
<h4 class="author"><em>Ernst-August Doelle</em></h4>
<address class="author_afil">
1,2<br><div class="abstract">
<p class="abstract">Abstract</p>
<p>One or two sentences providing a <strong>basic introduction</strong> to the field, comprehensible to a scientist in any discipline.</p>
<p>Two to three sentences of <strong>more detailed background</strong>, comprehensible to scientists in related disciplines.</p>
<p>One sentence clearly stating the <strong>general problem</strong> being addressed by this particular study.</p>
<p>One sentence summarizing the main result (with the words “<strong>here we show</strong>” or their equivalent).</p>
<p>Two or three sentences explaining what the <strong>main result</strong> reveals in direct comparison to what was thought to be the case previously, or how the main result adds to previous knowledge.</p>
<p>One or two sentences to put the results into a more <strong>general context</strong>.</p>
</div>

</div>


<div id="ggplot2-dataframes" class="section level1">
<h1>02/25/19 GGplot2 &amp; dataframes</h1>
<p>Table for a data frame: srt dim age subject live 200 dim 17 1 bk 300 bright</p>
<pre class="r"><code>Namess&lt;- c(&quot;peter&quot;,&quot;paul&quot;,&quot;mary&quot;,NA)
Ages &lt;- c(1000,1200,100,50) #if you have a 4th variable in only one category then you have to add NA in the others so it equals in length
Sex&lt;- c(&quot;M&quot;,&quot;M&quot;,&quot;F&quot;,NA)

my_df&lt;-data.frame(Names = Namess,
                  Age = Ages,
                  Sex = Sex)
#my_df$ #gives you all the columns

#names is saved as a factor

#my_df$Namess&lt;-as.character(my_df$Namess)</code></pre>
<p>once you get data into a long format table, the graph is easy</p>
<pre class="r"><code>library(ggplot2)
# Create dataframe
a &lt;- c(1,2,3,2,3,4,5,4)
b &lt;- c(4,3,4,3,2,1,2,3)
plot_df &lt;- data.frame(a,b)

# basic scatterplot
ggplot(data =plot_df, aes(x=a,y=b))+
  geom_point()</code></pre>
<p><img src="Class_Notes_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code># customize, add regression line
ggplot(data = plot_df, aes(x=a,y=b))+
  geom_point(size=2)+
  geom_smooth(method=lm)+
  coord_cartesian(xlim=c(0,7),ylim=c(0,10))+  #controls the range of the graph (left to right)
  xlab(&quot;x-axis label&quot;)+
  ylab(&quot;y-axis label&quot;)+
  ggtitle(&quot;I made a scatterplot&quot;)+
  theme_classic(base_size=12)+  #changes the background &amp; controls the font size, guaranteeing that it will stay that way.
  theme(plot.title = element_text(hjust = 0.5))</code></pre>
<p><img src="Class_Notes_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<pre class="r"><code>#Create a dataframe
factor_one &lt;- as.factor(c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;))
dv_means &lt;- c(20,30,40)
dv_SEs   &lt;- c(4,3.4,4)
plot_df &lt;- data.frame(factor_one,
                      dv_means,
                      dv_SEs)

# basic bar graph

ggplot(plot_df, aes(x=factor_one,y=dv_means))+ #set what will be x axis and what will be the y axis. have a plus to tell it you&#39;re adding another layer
  geom_bar(stat=&quot;identity&quot;) #stat = identity means dont touch the data statistically just plot it as is.</code></pre>
<p><img src="Class_Notes_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<pre class="r"><code># adding error bars, customizing

ggplot(plot_df, aes(x=factor_one,y=dv_means))+
  geom_bar(stat=&quot;identity&quot;)+
  geom_errorbar(aes(ymin=dv_means-dv_SEs,
                    ymax=dv_means+dv_SEs),
                width=.2)+
  coord_cartesian(ylim=c(0,100))+
  xlab(&quot;x-axis label&quot;)+
  ylab(&quot;y-axis label&quot;)+
  ggtitle(&quot;I made a bar graph&quot;)+
  theme_classic(base_size=12)+
  theme(plot.title = element_text(hjust = 0.5))</code></pre>
<p><img src="Class_Notes_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<pre class="r"><code>#Create a dataframe
factor_one &lt;- rep(as.factor(c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;)),2)
factor_two &lt;- rep(as.factor(c(&quot;IIA&quot;,&quot;IIB&quot;)),3)
dv_means &lt;- c(20,30,40,20,40,40)
dv_SEs   &lt;- c(4,3.4,4,3,2,4)
plot_df &lt;- data.frame(factor_one,
                      factor_two,
                      dv_means,
                      dv_SEs)

# basic bar graph

ggplot(plot_df, aes(x=factor_one,y=dv_means,
                    group=factor_two,
                    color=factor_two, # color = only for border
                    fill=factor_two))+
  geom_bar(stat=&quot;identity&quot;, position=&quot;dodge&quot;,color=&quot;black&quot;) #dodge makes the bars next to each other, without dodge theyre on top of each other</code></pre>
<p><img src="Class_Notes_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<pre class="r"><code># adding error bars, customizing

ggplot(plot_df, aes(x=factor_one,y=dv_means,
                    group=factor_two,
                    color=factor_two,
                    fill=factor_two))+
  geom_bar(stat=&quot;identity&quot;, position=&quot;dodge&quot;)+
  geom_errorbar(aes(ymin=dv_means-dv_SEs,
                    ymax=dv_means+dv_SEs),
                position=position_dodge(width=0.9), #important to make error bars look right
                width=.2,
                color=&quot;black&quot;)+
  coord_cartesian(ylim=c(0,100))+
  xlab(&quot;x-axis label&quot;)+
  ylab(&quot;y-axis label&quot;)+
  ggtitle(&quot;Bar graph 2 factors&quot;)+
  theme_classic(base_size=12)+
  theme(plot.title = element_text(hjust = 0.5))</code></pre>
<p><img src="Class_Notes_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<pre class="r"><code>#Create a dataframe
factor_one &lt;- rep(rep(as.factor(c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;)),2),2)
factor_two &lt;- rep(rep(as.factor(c(&quot;IIA&quot;,&quot;IIB&quot;)),3),2)
factor_three &lt;- rep(as.factor(c(&quot;IIIA&quot;,&quot;IIIB&quot;)),each=6)
dv_means &lt;- c(20,30,40,20,40,40,
              10,20,50,50,10,10)
dv_SEs   &lt;- c(4,3.4,4,3,2,4,
              1,2,1,2,3,2)
plot_df &lt;- data.frame(factor_one,
                      factor_two,
                      factor_three,
                      dv_means,
                      dv_SEs)

# basic bar graph

ggplot(plot_df, aes(x=factor_one,y=dv_means,
                    group=factor_two,
                    color=factor_two))+
  geom_bar(stat=&quot;identity&quot;, position=&quot;dodge&quot;)+
  facet_wrap(~factor_three) # breaks it into 2 graphs</code></pre>
<p><img src="Class_Notes_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<pre class="r"><code>Namez&lt;- rep(c(&quot;Dara&quot;,&quot;Azalea&quot;,&quot;Barbi&quot;,&quot;Rowena&quot;,&quot;Fiona&quot; ),each=2)
MF &lt;- rnorm(10,45,25)
Condition &lt;- rep(c(&quot;Social&quot;, &quot;Nonsocial&quot;),5)
Aversion &lt;- rep(c(&quot;A&quot;,&quot;N_A&quot;),times=c(4,6))
plot_df&lt;- data.frame(Namez,MF,Condition,Aversion)

ggplot(plot_df, aes(x=Condition, y=MF, group=Namez,linetype=Aversion))+
  geom_line()+
  geom_text(label=Namez)+
  theme_classic()</code></pre>
<p><img src="Class_Notes_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
</div>
<div id="snow-day" class="section level1">
<h1>03/04/19 Snow Day</h1>
<div id="what-is-data-wrangling" class="section level2">
<h2>What is Data-wrangling</h2>
<p>Data-wrangling is the general process of organizing and transforming data into various formats. For example, loading data into R, pre-processing it to get rid of things you don’t want and keep the things you want, add new things you might want that, arranging the data in different ways to accomplish different kinds of tasks, grouping the data, and summarizing the data, are all common data-wrangling activities. Real-world data often has many imperfections, so data-wrangling is necessary to get the data into a state that is readily analyzable.</p>
<p>We will mainly go over the <code>dplyr</code> package, which has a number of fantastic and relatively easy to use tools for data-wrangling. At the same time, it worth developigng your basic programming skills (using loops and logic), as they are also indispensable for solving unusual data-wrangling problems.</p>
</div>
<div id="dplyr-basics" class="section level2">
<h2>dplyr basics</h2>
<ol style="list-style-type: decimal">
<li><a href="https://dplyr.tidyverse.org">Dplyr reference</a></li>
<li><a href="http://r4ds.had.co.nz/transform.html">Hadley Wickham’s, R for Data Science, Chapter 5 Data transformation</a></li>
</ol>
<pre class="r"><code>library(dplyr) #load the package (make sure it is installed first)
df &lt;- starwars # dplyr comes with a data.frame called starwars</code></pre>
<p>Take a look at that data in df, what do you see? It lists various characters from starwars, along with many columns that code for different properties of each character</p>
</div>
<div id="basic-dataframe-stuff-without-dplyr" class="section level2">
<h2>basic dataframe stuff without dplyr</h2>
<pre class="r"><code># addressing specific columns
df$name 
df$height
df$mass
# addressing columns and rows without names
df[1,] # row 1
df[,1] # column 1
df[1:4,] # all of the data in rows 1:4
df[,4:5] # all of the data in columns 4:5
df[1:3,6:7] # the data in rows 1 to 3, for column 6 and 7 only
# finding a row(s) with specific info
df[df$name==&quot;Luke Skywalker&quot;,]
df[df$height &gt; 180,]
df[df$height &lt; 180 &amp; df$height &gt; 70,]
#replace a particular value
df[1,2] &lt;- 173 #changes the cell in row 1 column 2
# size of dataframe
dim(df) #c(number of rows, number of columns)
# cbind to add a column to a data.frame
df &lt;- cbind(df, random_number=runif(dim(df)[1],0,1))
# rbind to add rows
# this creates a new data frame, binding together the rows 1-2, and 5-6
# note: all of the columns need to be the same
new_df &lt;- rbind(df[1:2,],df[5:6,]) 
# convert a character vector to a factor
df$species &lt;- as.factor(df$species)
levels(df$species)
levels(df$species)[3] &lt;- &quot;hello&quot; # renames the third level, which get&#39;s applied to all listings in the df</code></pre>
</div>
<div id="a-couple-questions" class="section level2">
<h2>A couple questions:</h2>
<ol style="list-style-type: decimal">
<li>What are the names of all the characters who are taller than 80, shorter than 140, and are female?</li>
</ol>
<pre class="r"><code>df[df$height &gt; 80 &amp;
     df$height &lt; 170 &amp;
     df$gender == &quot;female&quot;, ]$name</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>How many characters have Tatooine for their homeworld?</li>
</ol>
<pre class="r"><code>df[df$homeworld==&quot;Tatooine&quot;,]
dim(df[df$homeworld==&quot;Tatooine&quot;,])[1] # counts the NAs
tatooine &lt;- df[df$homeworld==&quot;Tatooine&quot;,]
tatooine[is.na(tatooine$name)==FALSE,]
dim(tatooine[is.na(tatooine$name)==FALSE,])[1]</code></pre>
</div>
<div id="dplyr-style" class="section level2">
<h2>dplyr style</h2>
<p>We now look at dplyr and pipes. The idea here is that we start with a dataframe, then systematically transform one step at a time. At each step we pass the data in it’s new state to the next step. The passing is called piping the data. There is a special operator for this <code>%&gt;%</code></p>
<div id="quick-example" class="section level3">
<h3>quick example</h3>
<p>We start with the entire dataframe <code>df</code>. Then we select only the rows where the height is taller than 100. Then we group by homeworld, and compute the mean birth year. What we get is a new data.frame, showing the mean birth years for each homeworld.</p>
<p>This is a common refrain:</p>
<p>Dataframe %&gt;% filter %&gt;% group_by %&gt;% summarise</p>
<pre class="r"><code>library(dplyr)

new_df &lt;- df %&gt;%
            filter(height &gt; 100) %&gt;%
            group_by(homeworld) %&gt;%
            summarise(mean_birth_year = mean(birth_year,na.rm=TRUE))</code></pre>
</div>
<div id="filter" class="section level3">
<h3>filter</h3>
<p>We can filter the data by properties of particular columns</p>
<pre class="r"><code># make a new dataframe that only include rows where the height is greater than 120
new_df &lt;- df %&gt;%
        filter(height &gt; 120)
# multiple filters are seperated by a comma
new_df &lt;- df %&gt;%
        filter(height &gt; 120,
               height &lt; 180,
               birth_year &gt; 20)
# more examples of differen logical operators
new_df &lt;- df %&gt;%
        filter(gender == &quot;male&quot;) # == equals identity (same as)
new_df &lt;- df %&gt;%
        filter(gender != &quot;male&quot;) # != not equal to
new_df &lt;- df %&gt;%
        filter(eye_color %in% c(&quot;blue&quot;,&quot;yellow&quot;) == TRUE) # looks for matches to blue and yellow
# &lt;= less than or equal to
# &gt;= greater than or equal to
new_df &lt;- df %&gt;%
        filter(height &gt;= 120,
               height &lt;= 180) 
new_df &lt;- df %&gt;%
        filter(height &gt; 120 &amp; height &lt; 180) # &amp;  AND
new_df &lt;- df %&gt;%
        filter(skin_color == &quot;fair&quot; | skin_color == &quot;gold&quot;) # | OR</code></pre>
</div>
<div id="group_by-and-summarise" class="section level3">
<h3>group_by and summarise</h3>
<p><code>group_by()</code> let’s us grab parts of the data based on the levels in the column</p>
<p><code>summarise()</code> applies a function to each of the groups that are created</p>
<pre class="r"><code># counts the number of names, for each hair color
new_df &lt;- df %&gt;%
          group_by(hair_color) %&gt;%
          summarise(counts=length(name))
# counts names, for each combination of hair and eye color
new_df &lt;- df %&gt;%
          group_by(hair_color,eye_color) %&gt;%
          summarise(counts=length(name))</code></pre>
</div>
<div id="focus-on-summarise" class="section level3">
<h3>focus on summarise</h3>
<p><code>summarise</code> is very powerful. Using summarise we can apply any function we want to each of the groups. This includes intrinsic R functions, and functions of our own design. And, we can add as many as we want. What we get back are new dataframes with columns for each group, and new columns with variables containing the data we want from the analysis</p>
<pre class="r"><code>new_df &lt;- df %&gt;%
          group_by(hair_color,eye_color) %&gt;%
          summarise(mean_years = mean(birth_year,na.rm=TRUE),
                    sd_years = sd(birth_year,na.rm=TRUE),
                    counts = length(name))</code></pre>
</div>
<div id="mutate" class="section level3">
<h3>Mutate</h3>
<p>Use mutate to change or add a column</p>
<pre class="r"><code># change numbers in the height column by subtracting 100
library(dplyr)
new_df &lt;- df %&gt;%
            mutate(height=height-100)
# make a new column dividing height by mass
new_df &lt;- df %&gt;%
            mutate(hm_ratio = height/mass)</code></pre>
</div>
<div id="select" class="section level3">
<h3>Select</h3>
<p>Use select to select columns of interest and return a dataframe only with those columns</p>
<pre class="r"><code>new_df &lt;- df %&gt;%
            select(name,height,mass)</code></pre>
</div>
<div id="star-wars-questions-and-answers" class="section level3">
<h3>Star wars questions and answers</h3>
<ol style="list-style-type: decimal">
<li>use dplyr to find how many movies each character appeared in. Return a table that lists the names, and the number of films</li>
</ol>
<pre class="r"><code># two ways to do the same thing
new_df &lt;- df %&gt;% 
            select(name,films) %&gt;%
            group_by(name) %&gt;%
            mutate(films = length(unlist(films)))
new_df &lt;- df %&gt;% 
            select(name,films) %&gt;%
            group_by(name) %&gt;%
            summarise(films = length(unlist(films)))</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>How many characters are in each movie?</li>
</ol>
<ul>
<li>dplyr isn’t always necessary for every question</li>
</ul>
<pre class="r"><code>table(unlist(df$films))</code></pre>
<pre><code>## 
##              A New Hope    Attack of the Clones      Return of the Jedi 
##                      18                      40                      20 
##     Revenge of the Sith The Empire Strikes Back       The Force Awakens 
##                      34                      16                      11 
##      The Phantom Menace 
##                      34</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>What is the mean height and mass of characters with blue eyes?</li>
</ol>
<pre class="r"><code>new_df &lt;- df %&gt;%
            filter(eye_color==&quot;blue&quot;) %&gt;%
            summarise(mean_height = mean(height,na.rm=TRUE),
                      mean_mass = mean(mass,na.rm=TRUE))</code></pre>
</div>
</div>
<div id="data-input" class="section level2">
<h2>Data input</h2>
<p>Before we wrangle with data, we need to get it into R. There are many ways to do that.</p>
<p>All of the following examples assume you have a data folder in your workspace that contains all the data files we will be using. Download this .zip file <a href="https://github.com/CrumpLab/statisticsLab/raw/master/RstudioCloud.zip" class="uri">https://github.com/CrumpLab/statisticsLab/raw/master/RstudioCloud.zip</a>. Unzip the file. Then copy the data folder into your R markdown project folder.</p>
<p><strong>WARNING:</strong> loading files requires you to tell R exactly where the file is on your computer. This can involve specifying the entire file path (the drive, all of the folder, and then the filename). These examples avoid this complete filename nonsense by putting the files in a data folder in your R project folder. Then, we just need to specify the folder and the filename. In this case, the folder will always be data. In general, R by default attempts to load files from the current working directory, which is automatically set to your project folder when you are working in an R-studio project.</p>
<pre class="r"><code># loading a csv file using read.csv
hsq &lt;- read.csv(&quot;RstudioCloud/data/hsq.csv&quot;)
# alternative using fread
library(data.table)
hsq &lt;- fread(&quot;RstudioCloud/data/hsq.csv&quot;) # creates a data.table, similar to a data.frame
# loading an SPSS sav file
library(foreign)
spss &lt;- read.spss(&quot;RstudioCloud/data/02_NYC_Salary_City_2016.sav&quot;,
                  to.data.frame=TRUE)</code></pre>
<div id="other-helpful-libraries-for-reading-in-files" class="section level3">
<h3>Other helpful libraries for reading in files</h3>
<ol style="list-style-type: decimal">
<li>libary <code>readxl</code> let’s you read in excel files</li>
<li>library <code>googlesheets</code> let’s you read in google spreadsheets</li>
<li>function <code>scan</code> is a powerful and all purpose text input function, often helpful in very messy situations where you want to read in line-by-line</li>
<li><code>load</code> for R data files</li>
<li>there are several <code>read.</code> functions for specific situations.</li>
<li>library <code>jsonlite</code> for json data structures</li>
<li>and many more, this is really something that you will learn more about on a case-by-case basis as you have to deal with particular data formats.</li>
</ol>
</div>
</div>
</div>
<div id="going-over-data-wrangling" class="section level1">
<h1>03/11/19 Going over data wrangling</h1>
<pre class="r"><code>#strs(stimulus[1], split=&quot;&quot;)</code></pre>
<p>fig.path = “myfigs/”, dev = c(“pdf”, “png”)</p>
<p>^^ use in 1st chunk to save graphs</p>
</div>
<div id="statistics" class="section level1">
<h1>03/18/19 Statistics</h1>
<p>Discussing midterm assignment Part 1 (due April 1) 1. make a new github repository. put work into it. 2. find a psych paper with open data. - osf.io = open science framework - psychological science (look for blue badge) journals.sagepub.com - crumplab/statistics lab 3. load into r 4. re-analyse the data to see if you can reproduce the results from the original paper 5. write it up in reproducible report (.rmd file)</p>
<p>Part 2 (due April 1) 1. Convert your reproducible report into an APA style research report using papaja package.</p>
<p>Part 3 (due April 8) 1. Add a section following the results where you conduct and report a simulation based power analysis</p>
<p><strong>The most important thing about choosing statistics, is being able to justify the statistics that you choose.</strong></p>
<p>There are many tools in the toolbox. There are many recommendations about what to do or not to do. It is a good idea to understand the statistics that you use, so that you can justify why you are using them for your analysis.</p>
<div id="t-tests" class="section level2">
<h2>t-tests</h2>
<div id="one-sample-t-test" class="section level3">
<h3>one sample t-test</h3>
<p>Set <code>mu</code> to test against a population value</p>
<pre class="r"><code>x &lt;- c(1,4,3,2,3,4,3,2,3,2,3,4)
#non-directional
t.test(x, mu = 2)</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  x
## t = 3.0794, df = 11, p-value = 0.01048
## alternative hypothesis: true mean is not equal to 2
## 95 percent confidence interval:
##  2.237714 3.428952
## sample estimates:
## mean of x 
##  2.833333</code></pre>
<pre class="r"><code>t.test(x, mu = 2, alternative = &quot;two.sided&quot;) # the default</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  x
## t = 3.0794, df = 11, p-value = 0.01048
## alternative hypothesis: true mean is not equal to 2
## 95 percent confidence interval:
##  2.237714 3.428952
## sample estimates:
## mean of x 
##  2.833333</code></pre>
<pre class="r"><code># directional
t.test(x, mu = 2, alternative = &quot;greater&quot;)</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  x
## t = 3.0794, df = 11, p-value = 0.005241
## alternative hypothesis: true mean is greater than 2
## 95 percent confidence interval:
##  2.34734     Inf
## sample estimates:
## mean of x 
##  2.833333</code></pre>
<pre class="r"><code>t.test(x, mu = 2, alternative = &quot;less&quot;)</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  x
## t = 3.0794, df = 11, p-value = 0.9948
## alternative hypothesis: true mean is less than 2
## 95 percent confidence interval:
##      -Inf 3.319326
## sample estimates:
## mean of x 
##  2.833333</code></pre>
<p>t = mean/SEM SEM tells you how things vary</p>
</div>
<div id="paired-sample-t-test" class="section level3">
<h3>paired-sample t-test</h3>
<p>Set <code>paired=TRUE</code></p>
<pre class="r"><code>x &lt;- c(1,4,3,2,3,4,3,2,3,2,3,4)
y &lt;- c(3,2,5,4,3,2,3,2,1,2,2,3)
#non-directional
t.test(x, y, paired=TRUE)</code></pre>
<pre><code>## 
##  Paired t-test
## 
## data:  x and y
## t = 0.37796, df = 11, p-value = 0.7126
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.8038766  1.1372099
## sample estimates:
## mean of the differences 
##               0.1666667</code></pre>
<pre class="r"><code>t.test(x, y, paired=TRUE, alternative = &quot;two.sided&quot;) # the default</code></pre>
<pre><code>## 
##  Paired t-test
## 
## data:  x and y
## t = 0.37796, df = 11, p-value = 0.7126
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.8038766  1.1372099
## sample estimates:
## mean of the differences 
##               0.1666667</code></pre>
<pre class="r"><code># directional
t.test(x, y, paired=TRUE, alternative = &quot;greater&quot;)</code></pre>
<pre><code>## 
##  Paired t-test
## 
## data:  x and y
## t = 0.37796, df = 11, p-value = 0.3563
## alternative hypothesis: true difference in means is greater than 0
## 95 percent confidence interval:
##  -0.6252441        Inf
## sample estimates:
## mean of the differences 
##               0.1666667</code></pre>
<pre class="r"><code>t.test(x, y, paired=TRUE, alternative = &quot;less&quot;)</code></pre>
<pre><code>## 
##  Paired t-test
## 
## data:  x and y
## t = 0.37796, df = 11, p-value = 0.6437
## alternative hypothesis: true difference in means is less than 0
## 95 percent confidence interval:
##       -Inf 0.9585774
## sample estimates:
## mean of the differences 
##               0.1666667</code></pre>
</div>
<div id="independent-sample-t-test" class="section level3">
<h3>Independent sample t-test</h3>
<p>Note: Default is Welch test, set <code>var.equal=TRUE</code> for t-test</p>
<pre class="r"><code>x &lt;- c(1,4,3,2,3,4,3,2,3,2,3,4)
y &lt;- c(3,2,5,4,3,2,3,2,1,2,2,3)
#non-directional
t.test(x, y, var.equal=TRUE)</code></pre>
<pre><code>## 
##  Two Sample t-test
## 
## data:  x and y
## t = 0.40519, df = 22, p-value = 0.6893
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.6863784  1.0197117
## sample estimates:
## mean of x mean of y 
##  2.833333  2.666667</code></pre>
<pre class="r"><code>t.test(x, y, var.equal=TRUE, alternative = &quot;two.sided&quot;) # the default</code></pre>
<pre><code>## 
##  Two Sample t-test
## 
## data:  x and y
## t = 0.40519, df = 22, p-value = 0.6893
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.6863784  1.0197117
## sample estimates:
## mean of x mean of y 
##  2.833333  2.666667</code></pre>
<pre class="r"><code># directional
t.test(x, y, var.equal=TRUE, alternative = &quot;greater&quot;)</code></pre>
<pre><code>## 
##  Two Sample t-test
## 
## data:  x and y
## t = 0.40519, df = 22, p-value = 0.3446
## alternative hypothesis: true difference in means is greater than 0
## 95 percent confidence interval:
##  -0.5396454        Inf
## sample estimates:
## mean of x mean of y 
##  2.833333  2.666667</code></pre>
<pre class="r"><code>t.test(x, y, var.equal=TRUE, alternative = &quot;less&quot;)</code></pre>
<pre><code>## 
##  Two Sample t-test
## 
## data:  x and y
## t = 0.40519, df = 22, p-value = 0.6554
## alternative hypothesis: true difference in means is less than 0
## 95 percent confidence interval:
##       -Inf 0.8729787
## sample estimates:
## mean of x mean of y 
##  2.833333  2.666667</code></pre>
</div>
<div id="printing" class="section level3">
<h3>printing</h3>
<pre class="r"><code>library(broom)
t_results &lt;- t.test(x, y, var.equal=TRUE)
knitr::kable(tidy(t_results))</code></pre>
<table>
<thead>
<tr class="header">
<th align="right">estimate1</th>
<th align="right">estimate2</th>
<th align="right">statistic</th>
<th align="right">p.value</th>
<th align="right">parameter</th>
<th align="right">conf.low</th>
<th align="right">conf.high</th>
<th align="left">method</th>
<th align="left">alternative</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">2.833333</td>
<td align="right">2.666667</td>
<td align="right">0.4051902</td>
<td align="right">0.6892509</td>
<td align="right">22</td>
<td align="right">-0.6863784</td>
<td align="right">1.019712</td>
<td align="left">Two Sample t-test</td>
<td align="left">two.sided</td>
</tr>
</tbody>
</table>
</div>
<div id="writing" class="section level3">
<h3>writing</h3>
<p>The contents of R variables can be written into R Markdown documents.</p>
<p>t(22) =0.41, p = 0.689</p>
<pre class="r"><code># write your own function
report_t &lt;- function(x){
  return(paste(c(&quot;t(&quot;,round(x$parameter, digits=2),&quot;) &quot;,
        &quot;= &quot;,round(x$statistic, digits=2),&quot;, &quot;,
        &quot;p = &quot;,round(x$p.value, digits=3)), collapse=&quot;&quot;))
}
report_t(t_results)</code></pre>
<pre><code>## [1] &quot;t(22) = 0.41, p = 0.689&quot;</code></pre>
<pre class="r"><code>t_results</code></pre>
<pre><code>## 
##  Two Sample t-test
## 
## data:  x and y
## t = 0.40519, df = 22, p-value = 0.6893
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.6863784  1.0197117
## sample estimates:
## mean of x mean of y 
##  2.833333  2.666667</code></pre>
<p>The results of my t-test were t(22) = 0.41, p = 0.689.</p>
</div>
</div>
<div id="anova" class="section level2">
<h2>ANOVA</h2>
<p>F = T^2</p>
<p>Effect/Error</p>
<p>SS_Effect/DF1 –&gt; M^2 Eff / SS_Error/DF2 –&gt; M^2 Error</p>
<p>Requires data to be in long-format.</p>
<pre class="r"><code># example creation of 2x2 data 
Subjects &lt;- rep(1:10,each=4)
Factor1 &lt;- rep(rep(c(&quot;A&quot;,&quot;B&quot;), each = 2), 10)
Factor2 &lt;- rep(rep(c(&quot;1&quot;,&quot;2&quot;), 2), 10)
DV &lt;- rnorm(40,0,1)
all_data &lt;- data.frame(Subjects = as.factor(Subjects),
                       DV,
                       Factor1,
                       Factor2)</code></pre>
<div id="between-subjects-1-factor" class="section level3">
<h3>between-subjects 1 factor</h3>
<pre class="r"><code># run anova
aov_out &lt;- aov(DV~Factor1, all_data)
# summary
sum_out &lt;- summary(aov_out)
# kable xtable printing
library(xtable)
knitr::kable(xtable(summary(aov_out)))</code></pre>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Df</th>
<th align="right">Sum Sq</th>
<th align="right">Mean Sq</th>
<th align="right">F value</th>
<th align="right">Pr(&gt;F)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Factor1</td>
<td align="right">1</td>
<td align="right">0.9712296</td>
<td align="right">0.9712296</td>
<td align="right">1.071932</td>
<td align="right">0.3070536</td>
</tr>
<tr class="even">
<td>Residuals</td>
<td align="right">38</td>
<td align="right">34.4301122</td>
<td align="right">0.9060556</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
</tbody>
</table>
<pre class="r"><code># print means
print(model.tables(aov_out,&quot;means&quot;), format=&quot;markdown&quot;)</code></pre>
<pre><code>## Tables of means
## Grand mean
##            
## -0.1673187 
## 
##  Factor1 
## Factor1
##       A       B 
## -0.3231 -0.0115</code></pre>
<pre class="r"><code>sum_out[[1]]$`F value`[1]</code></pre>
<pre><code>## [1] 1.071932</code></pre>
<pre class="r"><code>#kable function good for making dataframes into pretty table</code></pre>
</div>
<div id="between-subjects-2-factor" class="section level3">
<h3>between-subjects 2 factor</h3>
<pre class="r"><code># run anova
aov_out &lt;- aov(DV~Factor1*Factor2, all_data)
# summary
summary(aov_out)</code></pre>
<pre><code>##                 Df Sum Sq Mean Sq F value Pr(&gt;F)
## Factor1          1   0.97  0.9712   1.093  0.303
## Factor2          1   1.39  1.3881   1.562  0.219
## Factor1:Factor2  1   1.05  1.0498   1.181  0.284
## Residuals       36  31.99  0.8887</code></pre>
<pre class="r"><code># kable xtable printing
library(xtable)
knitr::kable(xtable(summary(aov_out)))</code></pre>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Df</th>
<th align="right">Sum Sq</th>
<th align="right">Mean Sq</th>
<th align="right">F value</th>
<th align="right">Pr(&gt;F)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Factor1</td>
<td align="right">1</td>
<td align="right">0.9712296</td>
<td align="right">0.9712296</td>
<td align="right">1.092898</td>
<td align="right">0.3027991</td>
</tr>
<tr class="even">
<td>Factor2</td>
<td align="right">1</td>
<td align="right">1.3880989</td>
<td align="right">1.3880989</td>
<td align="right">1.561989</td>
<td align="right">0.2194384</td>
</tr>
<tr class="odd">
<td>Factor1:Factor2</td>
<td align="right">1</td>
<td align="right">1.0497591</td>
<td align="right">1.0497591</td>
<td align="right">1.181265</td>
<td align="right">0.2843224</td>
</tr>
<tr class="even">
<td>Residuals</td>
<td align="right">36</td>
<td align="right">31.9922542</td>
<td align="right">0.8886737</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
</tbody>
</table>
<pre class="r"><code># print means
print(model.tables(aov_out,&quot;means&quot;), format=&quot;markdown&quot;)</code></pre>
<pre><code>## Tables of means
## Grand mean
##            
## -0.1673187 
## 
##  Factor1 
## Factor1
##       A       B 
## -0.3231 -0.0115 
## 
##  Factor2 
## Factor2
##       1       2 
##  0.0190 -0.3536 
## 
##  Factor1:Factor2 
##        Factor2
## Factor1 1       2      
##       A  0.0251 -0.6714
##       B  0.0128 -0.0358</code></pre>
</div>
<div id="repeated-measures-1-factor" class="section level3">
<h3>repeated-measures 1 factor</h3>
<pre class="r"><code># run anova
aov_out &lt;- aov(DV~Factor1 + Error(Subjects/Factor1), all_data)
# summary
summary(aov_out)</code></pre>
<pre><code>## 
## Error: Subjects
##           Df Sum Sq Mean Sq F value Pr(&gt;F)
## Residuals  9  4.337  0.4819               
## 
## Error: Subjects:Factor1
##           Df Sum Sq Mean Sq F value Pr(&gt;F)
## Factor1    1  0.971  0.9712   0.496  0.499
## Residuals  9 17.620  1.9578               
## 
## Error: Within
##           Df Sum Sq Mean Sq F value Pr(&gt;F)
## Residuals 20  12.47  0.6237</code></pre>
<pre class="r"><code># kable xtable printing
library(xtable)
knitr::kable(xtable(summary(aov_out)))</code></pre>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Df</th>
<th align="right">Sum Sq</th>
<th align="right">Mean Sq</th>
<th align="right">F value</th>
<th align="right">Pr(&gt;F)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Residuals</td>
<td align="right">9</td>
<td align="right">4.3369481</td>
<td align="right">0.4818831</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td>Factor1</td>
<td align="right">1</td>
<td align="right">0.9712296</td>
<td align="right">0.9712296</td>
<td align="right">0.4960939</td>
<td align="right">0.4990397</td>
</tr>
<tr class="odd">
<td>Residuals1</td>
<td align="right">9</td>
<td align="right">17.6197832</td>
<td align="right">1.9577537</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td>Residuals2</td>
<td align="right">20</td>
<td align="right">12.4733808</td>
<td align="right">0.6236690</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
</tbody>
</table>
<pre class="r"><code># print means
print(model.tables(aov_out,&quot;means&quot;), format=&quot;markdown&quot;)</code></pre>
<pre><code>## Tables of means
## Grand mean
##            
## -0.1673187 
## 
##  Factor1 
## Factor1
##       A       B 
## -0.3231 -0.0115</code></pre>
</div>
<div id="repeated-measures-2-factor" class="section level3">
<h3>repeated-measures 2 factor</h3>
<pre class="r"><code># run anova
aov_out &lt;- aov(DV~Factor1*Factor2 + Error(Subjects/(Factor1*Factor2)), all_data)
# summary
summary(aov_out)</code></pre>
<pre><code>## 
## Error: Subjects
##           Df Sum Sq Mean Sq F value Pr(&gt;F)
## Residuals  9  4.337  0.4819               
## 
## Error: Subjects:Factor1
##           Df Sum Sq Mean Sq F value Pr(&gt;F)
## Factor1    1  0.971  0.9712   0.496  0.499
## Residuals  9 17.620  1.9578               
## 
## Error: Subjects:Factor2
##           Df Sum Sq Mean Sq F value Pr(&gt;F)
## Factor2    1  1.388  1.3881   1.726  0.221
## Residuals  9  7.239  0.8043               
## 
## Error: Subjects:Factor1:Factor2
##                 Df Sum Sq Mean Sq F value Pr(&gt;F)  
## Factor1:Factor2  1  1.050  1.0498   3.378 0.0992 .
## Residuals        9  2.797  0.3108                 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code># kable xtable printing
library(xtable)
knitr::kable(xtable(summary(aov_out)))</code></pre>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Df</th>
<th align="right">Sum Sq</th>
<th align="right">Mean Sq</th>
<th align="right">F value</th>
<th align="right">Pr(&gt;F)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Residuals</td>
<td align="right">9</td>
<td align="right">4.3369481</td>
<td align="right">0.4818831</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td>Factor1</td>
<td align="right">1</td>
<td align="right">0.9712296</td>
<td align="right">0.9712296</td>
<td align="right">0.4960939</td>
<td align="right">0.4990397</td>
</tr>
<tr class="odd">
<td>Residuals1</td>
<td align="right">9</td>
<td align="right">17.6197832</td>
<td align="right">1.9577537</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td>Factor2</td>
<td align="right">1</td>
<td align="right">1.3880989</td>
<td align="right">1.3880989</td>
<td align="right">1.7258326</td>
<td align="right">0.2214434</td>
</tr>
<tr class="odd">
<td>Residuals2</td>
<td align="right">9</td>
<td align="right">7.2387614</td>
<td align="right">0.8043068</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td>Factor1:Factor2</td>
<td align="right">1</td>
<td align="right">1.0497591</td>
<td align="right">1.0497591</td>
<td align="right">3.3781328</td>
<td align="right">0.0992313</td>
</tr>
<tr class="odd">
<td>Residuals</td>
<td align="right">9</td>
<td align="right">2.7967614</td>
<td align="right">0.3107513</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
</tbody>
</table>
<pre class="r"><code># print means
print(model.tables(aov_out,&quot;means&quot;), format=&quot;markdown&quot;)</code></pre>
<pre><code>## Tables of means
## Grand mean
##            
## -0.1673187 
## 
##  Factor1 
## Factor1
##       A       B 
## -0.3231 -0.0115 
## 
##  Factor2 
## Factor2
##       1       2 
##  0.0190 -0.3536 
## 
##  Factor1:Factor2 
##        Factor2
## Factor1 1       2      
##       A  0.0251 -0.6714
##       B  0.0128 -0.0358</code></pre>
</div>
<div id="papaja" class="section level3">
<h3>papaja</h3>
<pre class="r"><code>#library(papaja)
#apa_stuff &lt;- apa_print.aov(aov_out)</code></pre>
<pre class="r"><code>#The main effect for factor 1 was, `r apa_stuff$statistic$Factor1`. The main effect for factor 2 was, `r apa_stuff$statistic$Factor2`. The interaction was, `r apa_stuff$statistic$Factor1_Factor2`</code></pre>
</div>
</div>
<div id="linear-regression" class="section level2">
<h2>Linear Regression</h2>
<pre class="r"><code>lm(DV~Factor1, all_data)</code></pre>
<pre><code>## 
## Call:
## lm(formula = DV ~ Factor1, data = all_data)
## 
## Coefficients:
## (Intercept)     Factor1B  
##     -0.3231       0.3116</code></pre>
<pre class="r"><code>summary(lm(DV~Factor1, all_data))</code></pre>
<pre><code>## 
## Call:
## lm(formula = DV ~ Factor1, data = all_data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.61382 -0.56094 -0.09081  0.73849  2.01264 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)  -0.3231     0.2128  -1.518    0.137
## Factor1B      0.3116     0.3010   1.035    0.307
## 
## Residual standard error: 0.9519 on 38 degrees of freedom
## Multiple R-squared:  0.02743,    Adjusted R-squared:  0.001841 
## F-statistic: 1.072 on 1 and 38 DF,  p-value: 0.3071</code></pre>
<pre class="r"><code>lm(DV~Factor1+Factor2, all_data)</code></pre>
<pre><code>## 
## Call:
## lm(formula = DV ~ Factor1 + Factor2, data = all_data)
## 
## Coefficients:
## (Intercept)     Factor1B     Factor22  
##     -0.1369       0.3116      -0.3726</code></pre>
<pre class="r"><code>summary(lm(DV~Factor1+Factor2, all_data))</code></pre>
<pre><code>## 
## Call:
## lm(formula = DV ~ Factor1 + Factor2, data = all_data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.80011 -0.67105 -0.06665  0.60334  1.82635 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)  -0.1369     0.2588  -0.529    0.600
## Factor1B      0.3116     0.2988   1.043    0.304
## Factor22     -0.3726     0.2988  -1.247    0.220
## 
## Residual standard error: 0.945 on 37 degrees of freedom
## Multiple R-squared:  0.06665,    Adjusted R-squared:  0.01619 
## F-statistic: 1.321 on 2 and 37 DF,  p-value: 0.2792</code></pre>
<pre class="r"><code>lm(DV~Factor1*Factor2, all_data)</code></pre>
<pre><code>## 
## Call:
## lm(formula = DV ~ Factor1 * Factor2, data = all_data)
## 
## Coefficients:
##       (Intercept)           Factor1B           Factor22  
##           0.02514           -0.01235           -0.69657  
## Factor1B:Factor22  
##           0.64800</code></pre>
<pre class="r"><code>summary(lm(DV~Factor1*Factor2, all_data))</code></pre>
<pre><code>## 
## Call:
## lm(formula = DV ~ Factor1 * Factor2, data = all_data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.63811 -0.60893 -0.09186  0.67585  1.66435 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)        0.02514    0.29811   0.084    0.933
## Factor1B          -0.01235    0.42159  -0.029    0.977
## Factor22          -0.69657    0.42159  -1.652    0.107
## Factor1B:Factor22  0.64800    0.59621   1.087    0.284
## 
## Residual standard error: 0.9427 on 36 degrees of freedom
## Multiple R-squared:  0.0963, Adjusted R-squared:  0.02099 
## F-statistic: 1.279 on 3 and 36 DF,  p-value: 0.2964</code></pre>
</div>
<div id="randomization-test" class="section level2">
<h2>Randomization Test</h2>
<pre class="r"><code>A &lt;- c(1,2,3,4,5,6,7,8,9,10)
B &lt;- c(2,4,6,8,10,12,14,16,18,20)
all &lt;- c(A,B)
mean_difference &lt;- c()
for(i in 1:10000){
  shuffle &lt;- sample(all)
  newA &lt;- shuffle[1:10]
  newB &lt;- shuffle[11:20]
  mean_difference[i] &lt;- mean(newB)-mean(newA)
}
observed &lt;- mean(B)-mean(A)
length(mean_difference[mean_difference &gt;= observed])/10000</code></pre>
<pre><code>## [1] 0.0121</code></pre>
<pre class="r"><code>library(EnvStats)
twoSamplePermutationTestLocation(x=B, y=A, fcn = &quot;mean&quot;, 
                                 alternative = &quot;greater&quot;, 
                                 mu1.minus.mu2 = 0, 
                                 paired = FALSE, 
                                 exact = FALSE, 
                                 n.permutations = 10000, 
                                 seed = NULL, 
                                 tol = sqrt(.Machine$double.eps))</code></pre>
<pre><code>## 
## Results of Hypothesis Test
## --------------------------
## 
## Null Hypothesis:                 mu.x-mu.y = 0
## 
## Alternative Hypothesis:          True mu.x-mu.y is greater than 0
## 
## Test Name:                       Two-Sample Permutation Test
##                                  Based on Differences in Means
##                                  (Based on Sampling
##                                  Permutation Distribution
##                                  10000 Times)
## 
## Estimated Parameter(s):          mean of x = 11.0
##                                  mean of y =  5.5
## 
## Data:                            x = B
##                                  y = A
## 
## Sample Sizes:                    nx = 10
##                                  ny = 10
## 
## Test Statistic:                  mean.x - mean.y = 5.5
## 
## P-value:                         0.0111</code></pre>
</div>
<div id="correlation" class="section level2">
<h2>Correlation</h2>
<pre class="r"><code>x &lt;- rnorm(10,0,1)
y &lt;- rnorm(10,0,1)
cor(x,y)</code></pre>
<pre><code>## [1] -0.5337205</code></pre>
<pre class="r"><code>ranks1 &lt;- sample(1:10) 
ranks2 &lt;- sample(1:10)
cor(ranks1,ranks2, method = &quot;spearman&quot;)</code></pre>
<pre><code>## [1] -0.1393939</code></pre>
</div>
<div id="chi-square" class="section level2">
<h2>Chi-square</h2>
<pre class="r"><code>M &lt;- as.table(rbind(c(762, 327, 468), c(484, 239, 477)))
dimnames(M) &lt;- list(gender = c(&quot;F&quot;, &quot;M&quot;),
                    party = c(&quot;Democrat&quot;,&quot;Independent&quot;, &quot;Republican&quot;))
(Xsq &lt;- chisq.test(M))</code></pre>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  M
## X-squared = 30.07, df = 2, p-value = 2.954e-07</code></pre>
</div>
<div id="binomial-test" class="section level2">
<h2>binomial test</h2>
<pre class="r"><code>number_of_successes &lt;- 100
trials &lt;- 150
binom.test(x=number_of_successes, n=trials, p = 0.5,
           alternative = &quot;two.sided&quot;,
           conf.level = 0.95)</code></pre>
<pre><code>## 
##  Exact binomial test
## 
## data:  number_of_successes and trials
## number of successes = 100, number of trials = 150, p-value =
## 5.448e-05
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.5851570 0.7414436
## sample estimates:
## probability of success 
##              0.6666667</code></pre>
</div>
<div id="post-hoc-tests" class="section level2">
<h2>Post-hoc tests</h2>
<p>Many kinds of post-hoc tests can be done in R using base R functions, or functions from other packages.</p>
<p>At the same time, it is common for post-hoc comparison functions to be limited and specific in their functionality. So, if you can’t find an existing function to complete the analysis you want, you may have to modify, extend, or write your own function to do the job.</p>
<div id="pairwise-t-tests" class="section level3">
<h3>pairwise t-tests</h3>
<p>Performs all possible t-tests between the levels of a grouping factor. Can implement different corrections for multiple comparisons.</p>
<pre class="r"><code>df &lt;- airquality #loads the airquality data from base R
df$Month &lt;- as.factor(df$Month)
# default uses holm correction
pairwise.t.test(df$Ozone,df$Month)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  df$Ozone and df$Month 
## 
##   5       6       7       8      
## 6 1.00000 -       -       -      
## 7 0.00026 0.05113 -       -      
## 8 0.00019 0.04987 1.00000 -      
## 9 1.00000 1.00000 0.00488 0.00388
## 
## P value adjustment method: holm</code></pre>
<pre class="r"><code># use bonferroni correction
pairwise.t.test(df$Ozone,df$Month, p.adj=&quot;bonf&quot;)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  df$Ozone and df$Month 
## 
##   5       6       7       8      
## 6 1.00000 -       -       -      
## 7 0.00029 0.10225 -       -      
## 8 0.00019 0.08312 1.00000 -      
## 9 1.00000 1.00000 0.00697 0.00485
## 
## P value adjustment method: bonferroni</code></pre>
</div>
<div id="tukey-hsd-test" class="section level3">
<h3>tukey HSD test</h3>
<p>notes: the warpbreaks data.frame should be available in base R, you do not need to load it to be able to use it.</p>
<p>Doesn’t work with repeated measures ANOVAs.</p>
<pre class="r"><code>summary(fm1 &lt;- aov(breaks ~ wool + tension, data = warpbreaks))</code></pre>
<pre><code>##             Df Sum Sq Mean Sq F value  Pr(&gt;F)   
## wool         1    451   450.7   3.339 0.07361 . 
## tension      2   2034  1017.1   7.537 0.00138 **
## Residuals   50   6748   135.0                   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>TukeyHSD(fm1, &quot;tension&quot;, ordered = TRUE)</code></pre>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
##     factor levels have been ordered
## 
## Fit: aov(formula = breaks ~ wool + tension, data = warpbreaks)
## 
## $tension
##          diff        lwr      upr     p adj
## M-H  4.722222 -4.6311985 14.07564 0.4474210
## L-H 14.722222  5.3688015 24.07564 0.0011218
## L-M 10.000000  0.6465793 19.35342 0.0336262</code></pre>
</div>
<div id="fishers-lsd" class="section level3">
<h3>Fishers LSD</h3>
<p>Explanation of Fisher’s least significant difference test. <a href="https://www.utd.edu/~herve/abdi-LSD2010-pretty.pdf" class="uri">https://www.utd.edu/~herve/abdi-LSD2010-pretty.pdf</a></p>
<pre class="r"><code>library(agricolae)
data(sweetpotato)
model &lt;- aov(yield~virus, data=sweetpotato)
out   &lt;- LSD.test(model,&quot;virus&quot;, p.adj=&quot;bonferroni&quot;)</code></pre>
</div>
</div>
<div id="linear-contrasts" class="section level2">
<h2>Linear Contrasts</h2>
<pre class="r"><code># Create data for a one-way BW subjects, 4 groups
A &lt;- rnorm(n=10, mean=100, sd=25)
B &lt;- rnorm(n=10, mean=120, sd=25)
C &lt;- rnorm(n=10, mean=140, sd=25)
D &lt;- rnorm(n=10, mean=80, sd=25)
DV &lt;- c(A,B,C,D)
Conditions &lt;- as.factor(rep(c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;), each=10))
df &lt;- data.frame(DV,Conditions)
# one-way ANOVA
aov_out &lt;- aov(DV~Conditions, df)
summary(aov_out)</code></pre>
<pre><code>##             Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## Conditions   3  22572    7524   13.83 3.72e-06 ***
## Residuals   36  19589     544                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code># look at the order of levels
levels(df$Conditions)</code></pre>
<pre><code>## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot;</code></pre>
<pre class="r"><code># set up linear contrasts
c1 &lt;- c(.5, -.5, -.5, .5) # AD vs. BC
c2 &lt;- c(0, 0, 1, -1) # C vs. D
c3 &lt;- c(0, -1, 1, 0) # B vs. C
# create a contrast matrix
mat &lt;- cbind(c1,c2,c3)
# assign the contrasts to the group
contrasts(df$Conditions) &lt;- mat
# run the ANOVA
aov_out &lt;- aov(DV~Conditions, df)
# print the contrasts, add names for the contrasts
summary.aov(aov_out, split=list(Conditions=list(&quot;AD vs. BC&quot;=1, &quot;C vs. D&quot; = 2, &quot;B vs. C&quot;=3))) </code></pre>
<pre><code>##                         Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## Conditions               3  22572    7524  13.827 3.72e-06 ***
##   Conditions: AD vs. BC  1  18552   18552  34.093 1.14e-06 ***
##   Conditions: C vs. D    1   4007    4007   7.365   0.0101 *  
##   Conditions: B vs. C    1     12      12   0.023   0.8812    
## Residuals               36  19589     544                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>a &lt;- replicate(10000,t.test(rnorm(10,0,1))$p.value)
hist(a)</code></pre>
<p><img src="Class_Notes_files/figure-html/unnamed-chunk-48-1.png" width="672" /></p>
<pre class="r"><code>length(a[a&lt;.05])</code></pre>
<pre><code>## [1] 546</code></pre>
<pre class="r"><code>Fact1 &lt;- rep(c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), each=5)
DV &lt;- rnorm(n=15, mean=0, sd=1)
aov(DV~Fact1, all_data)</code></pre>
<p>anova = aov(formula, dataframe) aov(dependent variable ~ Factor, dataframe) ^ for a one factor anova</p>
<p>03/25/18 Papaja</p>
<p>Open new project i.e. test papaja (acts as a template) Make a new r markdown – from template option</p>
<p>back to stats bc papaja not working</p>
<pre class="r"><code>mean(rnorm(100000,0,1))</code></pre>
<pre><code>## [1] 0.000309264</code></pre>
<pre class="r"><code>save_means&lt;- c()
for(i in 1:10000){
    save_means[i]&lt;-mean(rnorm(10,0,1))
}


hist(save_means)</code></pre>
<p><img src="Class_Notes_files/figure-html/unnamed-chunk-50-1.png" width="672" /></p>
<pre class="r"><code>sd(save_means)</code></pre>
<pre><code>## [1] 0.3115906</code></pre>
<pre class="r"><code>mean(replicate(1000,mean(rnorm(10,0,1))))</code></pre>
<pre><code>## [1] 0.001716855</code></pre>
<pre class="r"><code>sd(replicate(1000,mean(rnorm(10,0,1))))</code></pre>
<pre><code>## [1] 0.3176535</code></pre>
<pre class="r"><code>hist(replicate(1000,sd(rnorm(10,0,1))))</code></pre>
<p><img src="Class_Notes_files/figure-html/unnamed-chunk-50-2.png" width="672" /></p>
<p>NULL</p>
<pre class="r"><code>A &lt;- rnorm(n=10,mean=0,sd=1)
B &lt;- rnorm(n=10,mean=0,sd=1)
mean_diff &lt;- mean(A-B)

mean_differ &lt;- replicate(10000, mean(rnorm(n=10,mean=0,sd=1))-mean(rnorm(n=10,mean=0,sd=1)))
hist(mean_differ)</code></pre>
<p><img src="Class_Notes_files/figure-html/unnamed-chunk-51-1.png" width="672" /></p>
<pre class="r"><code>sort(mean_differ)[9500] # critical value</code></pre>
<pre><code>## [1] 0.7476529</code></pre>
<p>TTEST</p>
<pre class="r"><code>real_ps&lt;- pt(q=c(.5,1,1.5,2,2.5), df=9)

t_s&lt;- replicate(100,t.test(rnorm(10,0,1),mu=0)$statistic)

hist(t_s)</code></pre>
<p><img src="Class_Notes_files/figure-html/unnamed-chunk-52-1.png" width="672" /></p>
<pre class="r"><code>sim_ps&lt;- c(length(t_s[t_s&lt;.5])/100,
length(t_s[t_s&lt;1])/100,
length(t_s[t_s&lt;1.5])/100,
length(t_s[t_s&lt;2])/100,
length(t_s[t_s&lt;2.5])/100)

real_ps - sim_ps</code></pre>
<pre><code>## [1]  0.075464350  0.048281802 -0.013925328 -0.008276412  0.003069086</code></pre>
<pre class="r"><code>sum(real_ps - sim_ps)</code></pre>
<pre><code>## [1] 0.1046135</code></pre>
<p>CORRELATION</p>
<pre class="r"><code>cor(rnorm(10,0,1),rnorm(10,0,1))</code></pre>
<pre><code>## [1] 0.0456425</code></pre>
<pre class="r"><code>hist(replicate(10000,cor(rnorm(10,0,1),rnorm(10,0,1))))</code></pre>
<p><img src="Class_Notes_files/figure-html/unnamed-chunk-53-1.png" width="672" /></p>
<pre class="r"><code>sim_rs &lt;- replicate(10000,cor(rnorm(10,0,1),rnorm(10,0,1)))
sort(abs(sim_rs))[9500]</code></pre>
<pre><code>## [1] 0.6375356</code></pre>
<p>F-DISTRIBUTION</p>
<pre class="r"><code>run_anova&lt;- function(){
A &lt;- rnorm(4,0,1)
B &lt;- rnorm(4,0,1)
C &lt;- rnorm(4,0,1)

conds&lt;- rep(c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;),each = 4)
DV &lt;- c(A,B,C)
der &lt;- data.frame(conds,DV)
sum_o &lt;-summary(aov(DV~conds,der))
return(sum_o[[1]]$`F value`[1]) 
}

sim_fs&lt;- replicate(10000,run_anova())

a.a&lt;-sort(sim_fs)[9500]

a.b&lt;- qf(.95,2,9)</code></pre>
</div>
</div>
<div id="more-papaja-power-analysis" class="section level1">
<h1>04/01/19 More Papaja &amp; Power Analysis</h1>
<p>papaja manual</p>
<pre class="r"><code># Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)</code></pre>
</div>
<div id="methods" class="section level1">
<h1>Methods</h1>
<p>We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study. <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) --></p>
<div id="participants" class="section level2">
<h2>Participants</h2>
</div>
<div id="material" class="section level2">
<h2>Material</h2>
</div>
<div id="procedure" class="section level2">
<h2>Procedure</h2>
</div>
<div id="data-analysis" class="section level2">
<h2>Data analysis</h2>
<p>We used r cite_r(“r-references.bib”) for all our analyses.</p>
</div>
</div>
<div id="results" class="section level1">
<h1>Results</h1>
<p>you can control sizing in the {r, fig.width, fig.height, out.height, out.width}</p>
<p><span class="citation">@R-base</span></p>
<pre class="r"><code>a&lt;- rnorm(100,0,1)
hist(a)</code></pre>
<div class="figure">
<img src="Class_Notes_files/figure-html/myfig-1.png" alt="this figure is a histogram" width="672" />
<p class="caption">
this figure is a histogram
</p>
</div>
<pre class="r"><code>a &lt;- c(1,2,3)
sapply(a, FUN=function(x){
  paste(x, &quot;a&quot;, sep = &quot;&quot;)
})</code></pre>
<pre><code>## [1] &quot;1a&quot; &quot;2a&quot; &quot;3a&quot;</code></pre>
<p>Power Analysis:</p>
<p><strong>Bold Claim</strong>: If you can’t simulate your data, you might not understand it very well.</p>
<p>This week on simulation shows you how to generate simulated data in R. There are many reasons to do this, including:</p>
<ol style="list-style-type: decimal">
<li>Develop a deeper understanding of the assumptions behind statistical tests</li>
<li>Sample-size planning and power-analysis</li>
<li>Understand how real data ought to behave given the assumptions you are making about the data.</li>
</ol>
<div id="null-hypothesis" class="section level2">
<h2>Null-hypothesis</h2>
<p>In general, the null-hypothesis is the hypothesis that your experimental manipulation didn’t work. Or, the hypothesis of no differences.</p>
<p>We can simulate null-hypotheses in R for any experimental design. We do this in the following way:</p>
<ol style="list-style-type: decimal">
<li>Use R to generate sample data in each condition of a design</li>
<li>Make sure the sample data comes from the very same distribution for all conditions (ensure that there are no differences)</li>
<li>Compute a test-statistic for each simulation, save it, then repeat to create the sampling distribution of the test statistic.</li>
<li>The sampling distribution of the test-statistic is the null-distribution. We use it to set an alpha criterion, and then do hypothesis testing.</li>
</ol>
<div id="null-for-a-t-test" class="section level3">
<h3>Null for a t-test</h3>
<pre class="r"><code># samples A and B come from the same normal distribution
A &lt;- rnorm(n=10,mean=10, sd=5)
B &lt;- rnorm(n=10,mean=10, sd=5)
# the pvalue for this one pretend simulation
t.test(A,B,var.equal=TRUE)$p.value</code></pre>
<pre><code>## [1] 0.3711599</code></pre>
<pre class="r"><code># running the simulation
# everytime we run this function we do one simulated experiment and return the p-value
sim_null &lt;- function(){
  A &lt;- rnorm(n=10,mean=10, sd=5)
  B &lt;- rnorm(n=10,mean=10, sd=5)
  return(t.test(A,B,var.equal=TRUE)$p.value)
}
# use replicate to run the sim many times
outcomes &lt;- replicate(1000,sim_null())
# plot the null-distribution of p-values
hist(outcomes)</code></pre>
<p><img src="Class_Notes_files/figure-html/unnamed-chunk-56-1.png" width="672" /></p>
<pre class="r"><code># proportion of simulated experiments had a p-value less than .05
length(outcomes[outcomes&lt;.05])/1000</code></pre>
<pre><code>## [1] 0.046</code></pre>
<p>We ran the above simulation 1000 times. By definition, we should get approximately 5% of the simulations returning a p-value less than .05. If we increase the number of simulations, then we will get a more accurate answer that converges on 5% every time.</p>
</div>
</div>
<div id="alternative-hypothesis" class="section level2">
<h2>Alternative hypothesis</h2>
<p>The very general alternative to the null hypothesis (no differences), is often called the <strong>alternative</strong> hypothesis: that the manipulation does cause a difference. More specifically, there are an infinite number of possible alternative hypotheses, each involving a difference of a specific size.</p>
<p>Consider this. How often will we find a p-value less than .05 if there was a mean difference of 5 between sample A and B. Let’s use all of the same parameters as before, except this time we sample from different distributions for A and B.</p>
<pre class="r"><code># make the mean for B 15 (5 more than A)
sim_alternative &lt;- function(){
  A &lt;- rnorm(n=10,mean=10, sd=5)
  B &lt;- rnorm(n=10,mean=15, sd=5)
  return(t.test(A,B,var.equal=TRUE)$p.value)
}
# use replicate to run the sim many times
outcomes &lt;- replicate(1000,sim_alternative())
# plot the distribution of p-values
hist(outcomes)</code></pre>
<p><img src="Class_Notes_files/figure-html/unnamed-chunk-57-1.png" width="672" /></p>
<pre class="r"><code># proportion of simulated experiments had a p-value less than .05
length(outcomes[outcomes&lt;.05])/1000</code></pre>
<pre><code>## [1] 0.537</code></pre>
<p>We programmed a mean difference of 5 between our sample for A and B, and we found p-values less than .05 a much higher proportion of the time. This is sensible, as there really was a difference between the samples (we put it there).</p>
</div>
<div id="power-and-effect-size" class="section level2">
<h2>Power and Effect Size</h2>
<p><strong>Power</strong>: the probability of rejecting a null-hypothesis, given that there is a true effect of some size.</p>
<p><strong>Effect-size</strong>: In general, it’s the assumed size of the difference. In the above example, we assumed a difference of 5, so the assumed effect-size was 5.</p>
<p>There are many other ways to define and measure effect-size. Perhaps the most common way is Cohen’s D. Cohen’s D expresses the mean difference in terms of standard deviation units. In the above example, both distributions had a standard deviation of 5. The mean for A was 10, and the mean for B was 15. Using Cohen’s D, the effect-size was 1. This is because 15 is 1 standard deviation away from 10 (the standard deviation is also 5).</p>
<p>When we calculated the proportion of simulations that returned a p-value less than .05, we found the power of the design to detect an effect-size of 1.</p>
<p>Power depends on three major things:</p>
<ol style="list-style-type: decimal">
<li>Sample-size</li>
<li>Effect-size</li>
<li>Alpha-criterion</li>
</ol>
<p>Power is a property of a design. The power of a design increases when sample-size increases. The power of a design increases when the actual true effect-size increases. The power of a design increases then the alpha criterion increases (e.g, going from .05 to .1, making it easier to reject the null).</p>
</div>
<div id="power-analysis-with-r" class="section level2">
<h2>Power analysis with R</h2>
<p>There are many packages and functions for power analysis. Power analysis is important for planning a design. For example, you can determine how many subjects you need in order to have a high probability of detecting a true effect (of a particular size) if it is really there.</p>
<div id="pwr-package" class="section level3">
<h3>pwr package</h3>
<p>Here is an example of using the <code>pwr</code> package to find the power for an independent sample t-test, with n=10, to detect an effect-size of 1. This answer is similar to our simulations answer. The simulation would converge on this answer if we increased the number of simulations.</p>
<pre class="r"><code>library(pwr)
pwr.t.test(n=10,
           d=1,
           sig.level=.05,
           type=&quot;two.sample&quot;,
           alternative=&quot;two.sided&quot;)</code></pre>
<pre><code>## 
##      Two-sample t test power calculation 
## 
##               n = 10
##               d = 1
##       sig.level = 0.05
##           power = 0.5620066
##     alternative = two.sided
## 
## NOTE: n is number in *each* group</code></pre>
<p>As I mentioned there are many functions for directly computing power in R. Feel free to use them. In this class, we learn how to use simulation to conduct power analyses. This can be a redundant approach that is not necessary, given there are other functions we can use. Additionally, we will not get exact solutions (but approximate ones). Nevertheless, the existing power functions can be limited and may not apply to your design. The simulation approach can be extended to any design. Learning how to run the simulations will also improve your statistical sensibilities, and power calculations will become less of a black box.</p>
<p>Two more things before moving onto simulation: power-curves, and sample-size planning.</p>
</div>
<div id="power-curves" class="section level3">
<h3>power-curves</h3>
<p>A design’s power is in relation to the true effect-size. The same design has different levels of power to detect different sized effects. Let’s make a power curve to see the power of a t-test for independent samples (n=10) to detect a range of effect-sizes</p>
<pre class="r"><code>effect_sizes &lt;- seq(.1,2,.1)
power &lt;- sapply(effect_sizes, 
          FUN = function(x) {
            pwr.t.test(n=10,
            d=x,
            sig.level=.05,
            type=&quot;two.sample&quot;,
            alternative=&quot;two.sided&quot;)$power})
plot_df &lt;- data.frame(effect_sizes,power)
library(ggplot2)
ggplot(plot_df, aes(x=effect_sizes,
                    y=power))+
  geom_point()+
  geom_line()</code></pre>
<p><img src="Class_Notes_files/figure-html/unnamed-chunk-59-1.png" width="672" /></p>
<p>This power curve applies to all independent-sample t-tests with n=10. It is a property, or fact about those designs. Every design has it’s own power curve. The power curve shows us what <strong>should</strong> happen (on average), when the <strong>true</strong> state of the world involves effects of different sizes.</p>
<p>If you do not know the power-curve for your design, then you do not know how sensitive your design is for detecting effects of particular sizes. You might accidentally be using an under powered design, with only a very small chance of detecting an effect of a size you are interested in.</p>
<p>If you do know the power-curve for your design, you will be in a better position to plan your experiment, for example by modifying the number of subjects that you run.</p>
</div>
<div id="sample-size-planning" class="section level3">
<h3>Sample-size planning</h3>
<p>Here is one way to plan for the number of subjects that you need to find an effect of interest.</p>
<ol style="list-style-type: decimal">
<li>Establish a smallest effect-size of interest</li>
<li>Create a curve showing the power of your design as a function of number of subjects to detect the smallest effect-size of interest.</li>
</ol>
<p>It’s not clear how you establish a smallest effect-size of interest. But let’s say you are interested in detecting an effect of at least d = .2. This means that two conditions would differ by at least a .2 standard deviation shift. If you find something smaller than that, let’s say you wouldn’t care about it because it wouldn’t be big enough for you to care. How many subjects do you need to have a high powered design, one that would almost always reject the null-hypothesis?</p>
<p>This is for an independent samples t-test:</p>
<pre class="r"><code>num_subjects &lt;- seq(10,1000,10)
power &lt;- sapply(num_subjects, 
          FUN = function(x) {
            pwr.t.test(n=x,
            d=.2,
            sig.level=.05,
            type=&quot;two.sample&quot;,
            alternative=&quot;two.sided&quot;)$power})
plot_df &lt;- data.frame(num_subjects,power)
library(ggplot2)
ggplot(plot_df, aes(x=num_subjects,
                    y=power))+
  geom_point()+
  geom_line()</code></pre>
<p><img src="Class_Notes_files/figure-html/unnamed-chunk-60-1.png" width="672" /></p>
<p>Well, it looks like you need many subjects to have high power. For example, if you want to detect the effect 95% of the time, you would need around 650 subjects. It’s worth doing this kind of analysis to see if your design checks out. You don’t want to waste your time running an experiment that is designed to fail (even when the true effect is real).</p>
</div>
</div>
<div id="simulation-approach-to-power-calculations" class="section level2">
<h2>Simulation approach to power calculations</h2>
<p>The simulation approach to power analysis involves these steps:</p>
<ol style="list-style-type: decimal">
<li>Use R to sample numbers into each condition of any design.</li>
<li>You can set the properties (e.g., n, mean, sd, kind of distribution etc.) of each sample in each condition, and mimic any type of expected pattern</li>
<li>Analyze the simulated data to obtain a p-value (use any analysis appropriate to the design)</li>
<li>Repeat many times, save the p-values</li>
<li>Compute power by determining the proportion of simulated p-values that are less than your alpha criterion.</li>
</ol>
<p>For all simulations, increasing number of simulations will improve the accuracy of your results. We will use 1000 simulations throughout. 10,000 would be better, but might take just a little bit longer.</p>
<div id="simulated-power-for-a-t-test" class="section level3">
<h3>Simulated power for a t-test</h3>
<p>A power curve for n=10.</p>
<pre class="r"><code># function to run a simulated t-test
sim_power &lt;- function(x){
  A &lt;- rnorm(n=10,mean=0, sd=1)
  B &lt;- rnorm(n=10,mean=(0+x), sd=1)
  return(t.test(A,B,var.equal=TRUE)$p.value)
}
# vector of effect sizes
effect_sizes &lt;- seq(.1,2,.1)
# run simulation for each effect size 1000 times
power &lt;- sapply(effect_sizes, 
          FUN = function(x) {
            sims &lt;- replicate(1000,sim_power(x))
            sim_power &lt;- length(sims[sims&lt;.05])/length(sims)
            return(sim_power)})
# combine into dataframe
plot_df &lt;- data.frame(effect_sizes,power)
# plot the power curve
ggplot(plot_df, aes(x=effect_sizes,
                    y=power))+
  geom_point()+
  geom_line()</code></pre>
<p><img src="Class_Notes_files/figure-html/unnamed-chunk-61-1.png" width="672" /></p>
<p>In this case, there is no obvious benefit to computing the power-curve by simulation. The answer we get is similar to the answer we got before using the <code>pwr</code> package, but our simulation answer is more noisy. Why bother the simulation?</p>
<p>One answer to the why bother question is that you can simulate deeper aspects of the design and get more refined answers without having to work through the math.</p>
</div>
<div id="simulating-cell-size" class="section level3">
<h3>Simulating cell-size</h3>
<p>Many experimental designs involve multiple measurements, or trials, for each subject in each condition. How many trials should we require for each subject in each condition? Traditional power analysis doesn’t make it easy to answer this question. However, the power of a design will depend not only on the number subjects, but also the number trials used to estimate the mean for each subject in each condition.</p>
<p>Consider a simple Stroop experiment. The researcher is interested in measuring a Stroop effect of at least d=.1 (e.g., the difference between mean congruent trials is .1 standard deviations smaller than mean incongruent trials). How many subjects are required? And, how many trials should each subject perform in the congruent and incongruent conditions? Let’s use simulation to find out.</p>
<pre class="r"><code># function to run a simulated t-test
# nsubs sets number of subjects
# ntrials to change number of trials
# d sets effect size
# this is a paired sample test to model Stroop
sim_power &lt;- function(nsubs,ntrials,d){
  A &lt;- replicate(nsubs,mean(rnorm(n=ntrials,mean=0, sd=1)))
  B &lt;- replicate(nsubs,mean(rnorm(n=ntrials,mean=d, sd=1)))
  return(t.test(A,B,paired=TRUE)$p.value)
}
# vectors for number of subjects and trials
n_subs_vector &lt;- c(10,20,30,50)
n_trials_vector &lt;- c(10,20,30,50,100)
# a loop to run all simulations
power &lt;- c()
subjects &lt;- c()
trials &lt;- c()
i &lt;- 0 # use this as a counter for indexing
for(s in n_subs_vector){
  for(t in n_trials_vector){
    i &lt;- i+1
    sims &lt;- replicate(1000,sim_power(s,t,.1))
    power[i] &lt;- length(sims[sims&lt;.05])/length(sims)
    subjects[i] &lt;- s
    trials[i] &lt;- t
  }
}
# combine into dataframe
plot_df &lt;- data.frame(power,subjects,trials)
# plot the power curve
ggplot(plot_df, aes(x=subjects,
                    y=power,
                    group=trials,
                    color=trials))+
  geom_point()+
  geom_line()</code></pre>
<p><img src="Class_Notes_files/figure-html/unnamed-chunk-62-1.png" width="672" /></p>
<pre class="r"><code># a vectorized version of the loop
# run simulation for each effect size 1000 times
# power &lt;- outer(n_subs_vector,
#                n_trials_vector,
#                FUN = Vectorize(function(x,y) {
#                   sims &lt;- replicate(100,sim_power(x,y))  
#                   sim_power &lt;- length(sims[sims&lt;.05])/length(sims)
#                   return(sim_power)
#                }))</code></pre>
<p>To my eye, it looks like 30 subjects with 100 trials in each condition would give you a very high power to find a Stroop effect of d=.1.</p>
</div>
<div id="one-way-anova" class="section level3">
<h3>One-Way ANOVA</h3>
<p>Let’s extend our simulation based approach to the one-way ANOVA. Let’s assume a between-subjects design, with one factor that has four levels: A, B, C, and D. There will be 20 subjects in each group. What is the power curve for this design to detect effects of various size? Immediately, the situation becomes complicated, there are numerous ways that the means for A, B, C, and D could vary. Let’s assume the simplest case, three of them are the same, and one of them is different by some amount of standard deviations. We will compute the main effect, and report the proportion of significant experiments as we increase the effect size for the fourth group.</p>
<pre class="r"><code># function to run a simulated t-test
sim_power_anova &lt;- function(x){
  A &lt;- rnorm(n=20,mean=0, sd=1)
  B &lt;- rnorm(n=20,mean=0, sd=1)
  C &lt;- rnorm(n=20,mean=0, sd=1)
  D &lt;- rnorm(n=20,mean=(0+x), sd=1)
  df &lt;- data.frame(condition = as.factor(rep(c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;),each=20)),
                   DV = c(A,B,C,D))
  aov_results &lt;- summary(aov(DV~condition,df))
  #return the pvalue
  return(aov_results[[1]]$`Pr(&gt;F)`[1])
}
# vector of effect sizes
effect_sizes &lt;- seq(.1,2,.1)
# run simulation for each effect size 1000 times
power &lt;- sapply(effect_sizes, 
          FUN = function(x) {
            sims &lt;- replicate(1000,sim_power_anova(x))
            sim_power &lt;- length(sims[sims&lt;.05])/length(sims)
            return(sim_power)})
# combine into dataframe
plot_df &lt;- data.frame(effect_sizes,power)
# plot the power curve
ggplot(plot_df, aes(x=effect_sizes,
                    y=power))+
  geom_point()+
  geom_line()</code></pre>
<p><img src="Class_Notes_files/figure-html/unnamed-chunk-63-1.png" width="672" /></p>
<p>It looks like this design (1 factor, between-subjects, 20 subjects per group) has high power to detect an effect of d=1, specifically when one of the groups differs from the others by d=1.</p>
<p>However, most effects in psychology are smalls, d=.2 is very common. How, many subjects does this design require to have high power (let’s say above .95, although most people use .8) to detect that small effect?</p>
<pre class="r"><code>sim_power_anova &lt;- function(x){
  A &lt;- rnorm(n=x,mean=0, sd=1)
  B &lt;- rnorm(n=x,mean=0, sd=1)
  C &lt;- rnorm(n=x,mean=0, sd=1)
  D &lt;- rnorm(n=x,mean=.2, sd=1)
  df &lt;- data.frame(condition = as.factor(rep(c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;),each=x)),
                   DV = c(A,B,C,D))
  aov_results &lt;- summary(aov(DV~condition,df))
  #return the pvalue
  return(aov_results[[1]]$`Pr(&gt;F)`[1])
}
# vector of effect sizes
subjects &lt;- seq(10,1000,50)
# run simulation for each effect size 1000 times
power &lt;- sapply(subjects, 
          FUN = function(x) {
            sims &lt;- replicate(1000,sim_power_anova(x))
            sim_power &lt;- length(sims[sims&lt;.05])/length(sims)
            return(sim_power)})
# combine into dataframe
plot_df &lt;- data.frame(subjects,power)
# plot the power curve
ggplot(plot_df, aes(x=subjects,
                    y=power))+
  geom_point()+
  geom_line()</code></pre>
<p><img src="Class_Notes_files/figure-html/unnamed-chunk-64-1.png" width="672" /></p>
<p>The simulations suggests we need about 560 subjects in each group to have power .95 to detect the effect (d=.2). That’s a total of 2240 subjects. Reality can be surprising when it comes to power analysis. It is better to be surprised about your design before you run your experiment, not after.</p>
</div>
</div>
<div id="closing-thoughts" class="section level2">
<h2>Closing thoughts</h2>
<p>The simulation approach is powerful and flexible. It can be applied whenever you can formalize your assumptions about the data. And, your simulations can be highly customized to account for all kinds of nuances, like different numbers of subjects, different distributions, assumptions about noise, etc. If you are wondering what your design can do, maybe you should simulate it.</p>
</div>
<div id="more-examples" class="section level2">
<h2>More example(s)</h2>
<p>As I find time I will try to add more examples here, especially out of the box examples to illustrate how simulation can be applied.</p>
<div id="correlation-between-traits-and-behavior" class="section level3">
<h3>Correlation between traits and behavior</h3>
<p>A common research strategy is to measure putative correlations between people’s traits and their behavior. For example, a researcher might prepare a questionnaire with several questions. Perhaps the questions are about their political views, or about their life satisfaction, or anything else. The research might ask some group of people to answer the questions, and to also perform some task. At the end of the experiment, they might ask if different kinds of people (measured by the questionnaire) perform differently on the behavioral measure. For example, we might have people answer several questions about their openness to new experiences, we might also measure their performance on a working memory task. A research question might be, do people who are more open to experience perform better on a working memory task? The answer would lie in a correlation between the answers on the questions, and the performance on the task. Let’s simulate this kind of situation, say for 20 subjects. Each subject answers 20 questions, and they perform a behavioral task. At the end of the experiment, we correlate the answers on each question, with the performance on the task. What kind of correlations would we expect by chance alone? Let’s say the participants are all random robots. They answer each question randomly, and their performance on the behavioral task is sampled randomly from some normal distribution. If everything is random, shouldn’t we expect to find no correlations?</p>
<p>Details:</p>
<p>Let’s assume that each question involves a likert scale from 1 to 7. Each person randomly picks a number from 1 to 7 for each question. Let’s assume performance on the behavioral task is sampled from a normal distribution with mean = 0, and sd = 1.</p>
<pre class="r"><code># get 20 random answers for all 20 subjects and 20 questions
# columns will be individual subjects 1 to 20
# rows will be questions 1 to 20
questionnaire &lt;- matrix(sample(1:7,20*20, replace=TRUE),ncol=20)
# get 20 measures of performance on behavioral task
behavioral_task &lt;- rnorm(20,0,1)
# correlate behavior with each question
save_correlations &lt;-c()
for(i in 1:20){
  save_correlations[i] &lt;- cor(behavioral_task,questionnaire[i,])
}
# show histogram of 20 correlations
hist(save_correlations)</code></pre>
<p><img src="Class_Notes_files/figure-html/unnamed-chunk-65-1.png" width="672" /></p>
<p>The histogram shows that a range of correlations between individual questions and behavior can emerge just by chance alone. If you run the above code a few times, you will see that the histogram changes a bit because of random chance.</p>
<p>Oftentimes researchers might not know which question on the questionnaire is the best question. That is, the one that best correlates with behavior. Consider a researcher who computes all of the correlations between each question and behavior, and then chooses the question with highest correlation (positive or negative) as the best question. After all, it has the highest correlation. After choosing this question, they might suggest that behavior is strongly correlated with how people answer this question.</p>
<p>Let’s try to find out by simulation what kinds of large correlations can occur just by chance alone. We will run the above many times, and each time we will save the absolute value of the largest correlation between a question and behavior. Just how large can these correlations be by chance alone?</p>
<pre class="r"><code>save_max &lt;- c()
for( j in 1:10000){
  questionnaire &lt;- matrix(sample(1:7,20*20, replace=TRUE),ncol=20)
  behavioral_task &lt;- rnorm(20,0,1)
  
  save_correlations &lt;-c()
  for(i in 1:20){
    save_correlations[i] &lt;- cor(behavioral_task,questionnaire[i,])
  }
  save_max[j] &lt;- max(abs(save_correlations))
}
hist(save_max)</code></pre>
<p><img src="Class_Notes_files/figure-html/unnamed-chunk-66-1.png" width="672" /></p>
<p>The simulation shows that chance alone in this situation can produce very large correlations, as large as .8 or .9 (although not very often).</p>
<p>The situation changes somewhat if many more subjects are run. Let’s do the same as above, but run 200 subjects, rather than 20.</p>
<pre class="r"><code>save_max &lt;- c()
for( j in 1:10000){
  questionnaire &lt;- matrix(sample(1:7,200*20, replace=TRUE),ncol=200)
  behavioral_task &lt;- rnorm(200,0,1)
  
  save_correlations &lt;-c()
  for(i in 1:20){
    save_correlations[i] &lt;- cor(behavioral_task,questionnaire[i,])
  }
  save_max[j] &lt;- max(abs(save_correlations))
}
hist(save_max)</code></pre>
<p><img src="Class_Notes_files/figure-html/unnamed-chunk-67-1.png" width="672" /></p>
<p>Now, chance doesn’t do much better than .25.</p>
</div>
</div>
</div>
<div id="shiny-web-apps" class="section level1">
<h1>04/08/19 Shiny Web Apps</h1>
<p>first main chunk: lay out the website, where buttons go &amp; layout ui = user interface “shiny widgets” = button types &amp; etc i.e. sliderinput (name of thing,) fluid page = shiny function for setting up webpages, you can add a title under it under it is a sidebar layout and a main bar panel</p>
<p>2nd part of the app: server (the R side of the app)</p>
<p><a href="https://crumplab.github.io/psyc7709/Presentations/Shiny_tutorial.html" class="uri">https://crumplab.github.io/psyc7709/Presentations/Shiny_tutorial.html</a></p>
</div>
<div id="more-shiny-and-optimization" class="section level1">
<h1>04/15/19 More Shiny and Optimization</h1>
<div id="memory-management" class="section level2">
<h2>Memory management</h2>
<p>When you create objects in R, you are assigning part of your computer’s memory to represent the parts of the object. Generally speaking, your ability to create objects in R is limited by the memory of your computer. Additionally, the process of representing your object in memory takes time. So, memory management involves understanding how to efficiently represent information in memory.</p>
<p>The size of an object in memory depends on object class</p>
<pre class="r"><code># numeric by default
a &lt;- rep(0,1000)
object.size(a)</code></pre>
<pre><code>## 8048 bytes</code></pre>
<pre class="r"><code># as.character
a &lt;- as.character(rep(0,1000))
object.size(a)</code></pre>
<pre><code>## 8104 bytes</code></pre>
<pre class="r"><code># as.integer
a &lt;- as.integer(rep(0,1000))
object.size(a)</code></pre>
<pre><code>## 4048 bytes</code></pre>
<pre class="r"><code># as.double
a &lt;- as.double(rep(0,1000))
object.size(a)</code></pre>
<pre><code>## 8048 bytes</code></pre>
</div>
<div id="matrices-and-data-frames" class="section level2">
<h2>Matrices and data frames</h2>
<pre class="r"><code>b &lt;- matrix(0,ncol=10,nrow=100)
object.size(b)</code></pre>
<pre><code>## 8216 bytes</code></pre>
<pre class="r"><code>c &lt;- as.data.frame(matrix(0,ncol=10,nrow=100))
object.size(c)</code></pre>
<pre><code>## 9904 bytes</code></pre>
</div>
<div id="rprofvis" class="section level2">
<h2>Rprofvis</h2>
<pre class="r"><code>Rprof(tmp &lt;- tempfile())

a &lt;- matrix(0,nrow=2,ncol=1000)
for(i in 1:1000){
  a &lt;- rbind(a,rnorm(1000,0,1))
}

Rprof()
summaryRprof(tmp)</code></pre>
<pre><code>## $by.self
##         self.time self.pct total.time total.pct
## &quot;rbind&quot;      7.98    92.79       8.00     93.02
## &quot;eval&quot;       0.60     6.98       8.60    100.00
## &quot;rnorm&quot;      0.02     0.23       0.02      0.23
## 
## $by.total
##                          total.time total.pct self.time self.pct
## &quot;eval&quot;                         8.60    100.00      0.60     6.98
## &quot;block_exec&quot;                   8.60    100.00      0.00     0.00
## &quot;call_block&quot;                   8.60    100.00      0.00     0.00
## &quot;evaluate_call&quot;                8.60    100.00      0.00     0.00
## &quot;evaluate::evaluate&quot;           8.60    100.00      0.00     0.00
## &quot;evaluate&quot;                     8.60    100.00      0.00     0.00
## &quot;FUN&quot;                          8.60    100.00      0.00     0.00
## &quot;generator$render&quot;             8.60    100.00      0.00     0.00
## &quot;handle&quot;                       8.60    100.00      0.00     0.00
## &quot;in_dir&quot;                       8.60    100.00      0.00     0.00
## &quot;knitr::knit&quot;                  8.60    100.00      0.00     0.00
## &quot;lapply&quot;                       8.60    100.00      0.00     0.00
## &quot;process_file&quot;                 8.60    100.00      0.00     0.00
## &quot;process_group.block&quot;          8.60    100.00      0.00     0.00
## &quot;process_group&quot;                8.60    100.00      0.00     0.00
## &quot;render_one&quot;                   8.60    100.00      0.00     0.00
## &quot;rmarkdown::render_site&quot;       8.60    100.00      0.00     0.00
## &quot;rmarkdown::render&quot;            8.60    100.00      0.00     0.00
## &quot;sapply&quot;                       8.60    100.00      0.00     0.00
## &quot;suppressMessages&quot;             8.60    100.00      0.00     0.00
## &quot;timing_fn&quot;                    8.60    100.00      0.00     0.00
## &quot;withCallingHandlers&quot;          8.60    100.00      0.00     0.00
## &quot;withVisible&quot;                  8.60    100.00      0.00     0.00
## &quot;rbind&quot;                        8.00     93.02      7.98    92.79
## &quot;rnorm&quot;                        0.02      0.23      0.02     0.23
## 
## $sample.interval
## [1] 0.02
## 
## $sampling.time
## [1] 8.6</code></pre>
<pre class="r"><code>Rprof(tmp &lt;- tempfile())

a &lt;- matrix(0,nrow=1002,ncol=1000)

for(i in 3:1002){
  a[i,] &lt;- rnorm(1000,0,1)
}

Rprof()
summaryRprof(tmp)</code></pre>
<pre><code>## $by.self
##         self.time self.pct total.time total.pct
## &quot;rnorm&quot;      0.14     87.5       0.14      87.5
## &quot;eval&quot;       0.02     12.5       0.16     100.0
## 
## $by.total
##                          total.time total.pct self.time self.pct
## &quot;eval&quot;                         0.16     100.0      0.02     12.5
## &quot;block_exec&quot;                   0.16     100.0      0.00      0.0
## &quot;call_block&quot;                   0.16     100.0      0.00      0.0
## &quot;evaluate_call&quot;                0.16     100.0      0.00      0.0
## &quot;evaluate::evaluate&quot;           0.16     100.0      0.00      0.0
## &quot;evaluate&quot;                     0.16     100.0      0.00      0.0
## &quot;FUN&quot;                          0.16     100.0      0.00      0.0
## &quot;generator$render&quot;             0.16     100.0      0.00      0.0
## &quot;handle&quot;                       0.16     100.0      0.00      0.0
## &quot;in_dir&quot;                       0.16     100.0      0.00      0.0
## &quot;knitr::knit&quot;                  0.16     100.0      0.00      0.0
## &quot;lapply&quot;                       0.16     100.0      0.00      0.0
## &quot;process_file&quot;                 0.16     100.0      0.00      0.0
## &quot;process_group.block&quot;          0.16     100.0      0.00      0.0
## &quot;process_group&quot;                0.16     100.0      0.00      0.0
## &quot;render_one&quot;                   0.16     100.0      0.00      0.0
## &quot;rmarkdown::render_site&quot;       0.16     100.0      0.00      0.0
## &quot;rmarkdown::render&quot;            0.16     100.0      0.00      0.0
## &quot;sapply&quot;                       0.16     100.0      0.00      0.0
## &quot;suppressMessages&quot;             0.16     100.0      0.00      0.0
## &quot;timing_fn&quot;                    0.16     100.0      0.00      0.0
## &quot;withCallingHandlers&quot;          0.16     100.0      0.00      0.0
## &quot;withVisible&quot;                  0.16     100.0      0.00      0.0
## &quot;rnorm&quot;                        0.14      87.5      0.14     87.5
## 
## $sample.interval
## [1] 0.02
## 
## $sampling.time
## [1] 0.16</code></pre>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
